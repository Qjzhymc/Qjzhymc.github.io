---
title: Kafka消息队列面试题
author: Yu Mengchi
categories:
  - Interview 
  - 面试知识点
  - 中间件
tags:
  - Interview
  - 消息队列
---
  
# Kafka消息队列面试题

### 什么是Kafka？为什么要使用kafka？优点？

是一个分布式流处理平台，可以处理实时数据流，一般做消息队列使用。

为什么使用Kafka？
1. 实时数据处理：支持低延迟的消息传递；
2. 高吞吐量：能够处理大量数据，每秒可处理数百万条消息；
3. 持久性：支持数据写入磁盘，可以确保数据的持久性；
4. 扩展性：是分布式架构，容易扩展；

优点：
1. 解耦：生产者和消费者不需要直接交互，可以减少系统之间的依赖关系；更灵活、容错性高、可扩展性；
2. 削峰：流量高峰时期，Kakfa临时存储这些超额的消息，可以平滑负载，保护后端服务稳定；
3. 异步：支持异步消息传递，生产者发送消息后不用等待消费者的响应，可以提高性能。

---
### 发布订阅模型
发布订阅模型使用主题作为消息通信载体，类似于广播模式，发布者发布一条消息，该消息通过主题传递给所有的订阅者。

- Topic：topic是生产者和消费者通信的载体，生产者将消息发送到特定的topic上，消费者通过订阅特定的topic来消费消息。
- Partition：partition属于topic的一部分，一个topic可以有多个partition，并且同一topic下的partition可以分布在不同的broker上，
也就是说一个topic可以横跨多个broker。
- broker：broker可以看作是一个独立的kafka实例，多个kafka broker可以组成一个kafka 集群。

---
### 消息队列的重复消费、消息丢失、消息顺序等问题如何保证？


---
### Kafka的架构是什么？包括哪些组件？各个组件的作用是什么？
1. Broker：每台服务器就是一个Broker，Kafka集群就是由多个broker组成，负责处理客户端的请求，包括生产者发布的消息和消费者订阅的消息。
2. Topic：特定主题的消息流，消息通过Topic分类管理。每个主题分成多个pattition分区，每个分区都是一个有序的消息序列；
3. Partition：主题分成多个partition分区，每个partition分区都是有序的，但是不同分区之间的有序性无法保证，每个分区都有一个Leader和多个follower；
4. Producer生产者：负责向kafka的topic主题发送消息，可以把消息发送到特定的分区，也可以让kafka决定消息放到哪个分区；
5. consumer消费者：从topic主题中拉取消息。consumer group消费者组是一组消费者的集合，共同消费一组主题的所有分区，确保每个分区只被组内的一个消费者消费。
6. zookeeper：管理集群，帮助选举leader节点、监控节点健康状态。

---
### Kafka的消息是如何被存储和传输的？
存储
1. 在kafka消息是按主题topic组织的，每个主题可以分成多个partition分区，每个分区是一个有序的消息序列，新的消息会不断追加到分区末尾；
2. 每个partition分区实际上是一个commit log提交日志文件，消息会追加到日志文件里；
3. partition分区支持副本，每个分区可以有多个副本分布在不同的broker上，其中有一个leader，其他的都是follower，所有的读写操作都通过leader进行，follower从leader同步数据；

传输
1. producer负责将消息发送到指定的主题，可以选择将消息发送到特定的分区；
2. consumer订阅一个或多个主题，多个consumer可以组成一个consumer group，每个consumer只处理一部分分区的消息。确保每条消息只会被同一组内的一个消费者处理；

---
### Kafka的消息保证机制有哪些？如何保证消息的可靠性？
**什么叫消息可靠性**：就是确保消息一定能发送到服务器进行存储，并且发生宕机可以从备份数据中恢复。

- 第一、生产者能否保证发送的消息是可靠的；
- 第二、消费者能够可靠的消费消息；

1. 消息可以持久化，服务器崩溃了，也可以恢复数据；
2. 副本机制:每个topic的partition分区可以配置多个副本，其中一个作为leader，其他的都是follower，leader会处理所有的读写请求，follower会从leader同步数据，如果leader失败，会进行leader选举，可以保证系统的可用性和消息的可靠性；
3. **ack机制**：生产者在发送消息的时候可以选择不同的确认级别：
- acks = 0：表示生产者不会等待消息确认，可能消息会丢失；
- acks = 1：表示生产者会等待leader确认收到消息，但是不会等待所有follower同步完成；
- acks = all：表示生产者会等待ISR列表（in-sync replicas）中的所有follower确认收到消息。
4. offset机制：kafka可以让消费者控制什么时候提交offset偏移量。消费者可以自动提交或者手动提交，手动提交可以让程序控制什么时候一条消息才叫被成功处理了，可以避免重复消费或者消失丢失；

---
### Kafka的消费者是如何工作的？如何实现消息消费的负载均衡？

消费者的工作机制：
1. 消费者可以订阅一个或多个主题来消费消息，每个主题被划分成多个partition分区，每个分区是一个有序的消息队列；
2. 消费者会以pull拉取的方式从kafka集群获取消息；
3. 消费者会记录自己的offset偏移量，下次消费的是否可以从正确的位置继续读取；
4. 消费者通常以消费者组的形式工作，同一个消费者组内的消费者共同消费一个主题的消息，每个分区只能由一个消费者消费。不同消费者组之间的消费者是互不影响的，可以独立消费同一个主题的消息。

消息消费的负载均衡：
1. kafka的主题会划分成多个分区，在同一个消费者组里面，会把分区分配给不同的消费者，分区分配的目标是尽量让每个消费者处理相同数量的分区；
2. kafka有一些分区分配的策略，比如按范围分配，轮询分配，粘性分配（在保证均匀的同时，尽量减少分区重新分配的次数）
3. 动态再平衡：当消费者组内的消费者数量发生变化时，比如新增或移除消费者，kafka会触发再平衡操作
4. 一个分区只能给组内一个消费者消费；一个消费者可以消费多个分区。不同组的就互不影响

---
### Kafka的生产者是如何发送消息的？如何实现消息的批量发送？

发送消息流程：
1. 创建消息：包含key，value，topic，key用于分区选择，value是消息内容；
2. 分区选择：根据消息的key、分区策略或用户指定的分区号，选择消息要发送到的目标分区
3. 批量缓存：生产者会把消息缓存在内存中batch里，每个batch对应一个分区；
4. 发送请求：当batch.size满了，或者手动触发强制发送，会将所有batch打包成一个请求，发送到broker节点
5. 确认机制：生产者会有ack确认机制，决定消失是否发送成功
6. 重试机制：如果失败了，还会有重试机制。

如何实现消息的批量发送：
1. kafka会将多条消息打包成一个batch，一个batch对应一个分区，然后一次性发送给broker。
2. 批量发送的触发条件，批量的batch打到一定的条件就会一次性发送给broker，比如批次大小达到了batch.size大小、或者等待时间超时了、或者手动调用flush()强制发送。

---
### Kafka的消息大小有限制吗？如何处理大消息？

有，默认是1MB，参数是max.request.size

如何处理大消息：
1. 修改配置
- 修改broker的配置，leader和follower之间同步消息的最大配置；
- 修改producer的配置，修改发送端的最大发送配置；
- 修改consumer的配置，修改消费者拉取消息的最大拉取配置；
2. 拆分大消息
- 在生产者端拆分成多个小消息；
- 使用分区键确保所有消息都发送到同一个分区，保证顺序性；
- 在消费者端根据分区键将小消息重新组成成完整的大消息；
3. 存储大消息的引用
- 把大消息存储在外部系统，比如HDFS或数据库
- 将指向外部存储系统的引用作为消息发送；
- 消费时收到引用，读取实际数据。
4. 启动压缩：生产者端可以启动压缩

---
### Kafka的消费者如何处理重复消息？如何保证消息的有序性？

为什么会收到重复消息？
1. consumer group有消费者加入或退出，分区会被重新分配，可能导致重复消费；
2. offset没有成功提交；

避免重复消息解决方法：
1. 幂等性设计：确保消费者的业务逻辑是幂等性的，同一条消息被多次处理也不会产生副作用。比如可以通过数据库的唯一键约束避免重复操作；
2. Exactly once语义：使用kafka的事务功能，确保生产者和消费者之间的消息传递是exactly once精确一次的
3. 手动管理offset：在消费者手动控制offset的提交时机，确保只有消息成功处理完成后才提交offset值。

如何保证消息有序性：
1. **分区键**：把同一业务逻辑的消息用相同的分区键路由到同一个分区，保证相对有序
2. **单分区**：如果需要所有消息都有序，可以将所有消息都写到同一个分区。会牺牲吞吐量。
3. **消费者单线程处理**：每个分区只能由一个消费者线程处理，避免多线程并发处理导致乱序。
4. **手动提交offset**：确保消息按顺序处理完成后再提交偏移量

---
### Kafka的消息格式是什么？如何实现自定义消息格式？

kafka会把多条消息放在一个batch里，batch里面是一个个record，一个record就是一条消息，
record里面有：
1. key：用于分区分配
2. value：消息的实际内容
3. Headers：是一组键值对，用来存储一些和消息相关的上下文信息，比如时间戳、来源系统名字等
4. timestamp：每条消息都有一个timestamp，表示消息的生产时间
5. offset值：表示消息在分区中的位置
6. partition：可以指定放在哪个partition分区

---
### Kafka的分区机制是什么？如何实现分区的负载均衡？

分区机制就是指kafka中的每个topic主题会被划分成多个partition分区，每个分区是一个有序的消息队列，分区允许kafka在多个broker之间分布数据。

分区作用：
- 可以提交吞吐量，把数据分散到多个分区中，
- 水平扩展：可以增加分区数量扩展存储能力
- 容错性：每个分区有多个副本，可以提交容错性

如何实现分区的负载均衡：
- 生产者：有分区分配策略：比如轮询分配分区、按键值计算分区
- 消费者：同一个主题的所有消费者会组成一个消费者组，共同消费一个主题的所有分区，kafka会确保每个分区只被组内的一个消费者消费，避免重复消费，消费者数量增加或减少时会有再平衡机制，重新分配分区
- broker的负载均衡：kafka会尽量将分区均匀分布在集群中所有的broker上，每个分区都有一个leader和多个follower，kafka会动态调整leader和follower的角色，确保负载均衡。

---
### Kafka的副本机制是什么？如何实现副本的同步和选举？

一个主题会有多个分区，分区中有一个leader和多个follower，每个分区都会有一个leader副本，follower副本会从leader副本同步数据。

**副本集合**
- AR：assigned replicas 分配给分区的所有副本集合
- ISR：in-sync replicas 与leader保持同步的副本集合，包括leader本身和保持同步的follower
- OSR：out-of-sync replicas 没有与leader保持同步的副本集合

选举过程：
1. 故障检测：kafka的控制器会监控broker的状态，如果发现leader副本可以用，会触发选举
2. 选择新leader：优先从ISR列表中选择一个新的leader，如果ISR列表为空，则从OSR中选择一个副本
3. 更新元数据：新的leader信息会被更新到zookeeper，其他broker和消费者会感知到leader的变更。

---
### Kafka的高可用性是什么？如何保障Kafka的高可用性？

1. 副本机制：kafka为每个主题设置多个副本，副本分布在不同的broker上，每个分区都有一个leader和多个follower。生产者发送的消息首先发给leader，然后同步给follower；
2. ack机制：生产者可以控制消息的确认级别，避免数据丢失
3. 故障恢复机制：当leader所在的broker节点宕机时，kafka会从ISR列表中选举一个新的leader继续提供服务
4. offset管理：消费者可以手动提交消费进度，这样的话消费者故障重启后也不会重复消费数据或者丢失已经消费的数据

---
### Kafka的应用场景有哪些？如何根据不同场景使用Kafka？

1. 消息队列：解耦生产者和消费者，解耦、削峰、异步；
2. 日志聚合：收集日志数据，集中管理和分析；
3. 流处理：对实时数据流进行处理，比如过滤、聚合、转换。

---
### Kafka和其他消息队列的比较有哪些？Kafka的优势在哪里？

Kafka的特性：
1. 支持持久化数据到磁盘
2. 支持消费者组的概念，同一个组内的消费者不会重复消费相同的消息
3. 支持扩展，可以通过添加节点增加吞吐量和存储容量

优势：
1. 超高吞吐量
2. 持久化存储
3. 分布式架构
4. 实时处理能力
5. 灵活的消费模型：通过消费者组实现高效的消息负载均衡
6. 强大的生态系统：有很多客户端库、框架以及与大数据生态系统的良好集成。

---
### Kafka如何保证消息的有序性

- 一个topic只指定一个partition（不现实）
- 首先在同一个partition中消息肯定是有序的，发送消息的时候指定发到哪个partition和key，kafka发送一条消息的时候，可以指定topic、partition、key、data四个参数。我们可以
把同一key的消息都发送到同一个partition中。
保证将同一个语义下消息放到同一个partition分区中，比如一个订单有支付、发货、评价三条消息，要将同一个订单的这三条消息发送到同一个分区中，保证有序性。
具体做法可以用哈希取模。

> Kafka通过分区（partition）来保证消息有序性。每个分区内的消息都是有序的，
而且Kafka保证一个分区内的消息只能被一个消费者消费。因此，如果一个主题（topic）只有一个分区，
那么消息的顺序就是有序的。如果一个主题有多个分区，那么Kafka会根据消息的key来将消息分配到不同的分区中，
保证相同key的消息被分配到同一个分区中，从而保证消息的有序性。

---
### 如何保证消息不丢失？
- 生产端丢失：调用send方法发送之后使用回调函数判断是否发送成功
- 消费端丢失：关闭自动提交offset，只有真正消费了之后才提交offset值。但是会带来重复消费的问题
- Kafka丢失：设置acks=all，只有全部副本都收到消息才表示发送成功，但是这样延迟会很高；设置replication.factor>=3,保证每个分区有至少3个副本，保证数据安全；
min.insync.replica>=1,代表消息至少要被写入两个副本才表示发送成功。

> 需要配置kafka使用replication，kafka 的复制机制能够让每个分区保存多个副本，在不同的broker节点上，
> 生产者发送消息到topic之后，leader partition会复制到其他从节点上，保证消息在集群内不同节点上都有副本。
> 另外，可以设置acks=all，表示只有全部副本都收到消息才表示发送成功。

---
### Kafka如何保证消息的唯一性？如何保证不重复消费？
- 消费消息的服务做幂等校验，比如redis的set、mysql的主键；
保证消息消费的幂等还是需要结合具体业务来实现的，比如可以让消费的消息写入redis，保证新来的消息不再redis中，也就是保证这条消息之前没有被消费过。也可以把消费的消息写入数据库，基于数据库的唯一键，保证消息不会被重复插入多条。
- 关闭自动提交enable.auto.commit设置为false，开发者在消费后手动提交。
手动提交的时候如果是消费消息后再提交，还是会出现重复消费的现象。另一种是拉取到消息后就立马提交，这种情况如果拉取到消息，提交了offset，但此时服务端挂了，重启之后就可能有消息丢失，漏消费的情况，一般在允许消息延时的场景会使用这种方式。

---
### Kafka出现消息堆积怎么办？
一般情况出现消息堆积要么就是生产者发送消息太快或者是消费者消费太慢。
一般会增加消费者实例数量，同时也要增加分区数量，因为一个分区只会被一个消费者消费，只增加消费者实例不增加分区只会增加空闲的消费者实例。
另外如果是生产者消息发送太快的话，可能是系统出现流量高峰，应该在上游就考虑限流降级。
如果是消费者消费太慢的话，可以看看是不是消费过程中出现了异常，

---
### 零拷贝技术？
传统的数据传输方式需要将数据从磁盘或内存中复制到内核缓冲区，然后再从内核缓冲区复制到用户空间缓冲区，最后
在发送到网络中。kafka使用零拷贝技术，将数据从磁盘或内存中直接传输到网络中，避免了数据复制的过程。
具体实现就是，kafka使用了操作系统的文件映射机制，将数据映射到内存中，然后通过DMA（内存直接访问）技术                                                                                 
将数据直接传输到网络中，避免了数据在内存和网络之间的多次复制。

---
### Kafka为什么快？
1. 零拷贝技术：使用零拷贝技术，避免了数据在内存和网络之间的多次复制，从而提高了数据传输的效率
2. 批量发送：支持批量发送消息，减少网络传输开销，提高了吞吐量
3. 分区机制：将每个主题分为多个分区，每个分区可以独立地处理消息，提高并发性能和可伸缩性
4. 集群架构：采用分布式集群架构，可以将消息存储在多个服务器上，提高系统的可用性和可靠性。

---
### Kafka 的leader选举过程是怎样的？
所有broker会返回自己的偏移量和元数据，使用最新的偏移量和元数据来决定新的leader。

---
### 什么情况会触发leader选举？
1. 当leader宕机或失效
2. 当有新的副本被添加到分区中，
3. 当分区的副本数量发生变化
4. 当broker加入或离开集群时。

---
### 什么是ar、isr、osr？
1. AR：每个分区指定的副本列表，包括leader和follower
2. ISR：同步副本，与leader保持同步的副本列表。
3. OSR：不同步副本：不同步副本，由于网络故障与leader失去同步的副本列表

---
### Kafka的offset是什么？如何管理和维护offset？

---
### offset信息保持在哪里
保持在一个特殊的topic中，叫_consumer_offsets，存储了消费者组中每个消费者的分区偏移量信息，
每个偏移记录都包含了消费者组、消费者id、分区id和对应的偏移量。

---
### RocketMQ消息队列如何实现分布式事务？

消息队列中的事务指的是"发送端的本地事务"和"把消息发送到消息队列"这两个事件是属于同一个事务，要保证这两个操作要么都执行要么都不执行。

> 在RocketMQ中解决的方法就是使用事务消息加上事务反查机制来保证事务。发送端会发送事务消息给消息队列（事务消息也就是指half1消息，half消息暂时不会被消费端消费，会保存在另一个topic中，只有当发送端确定要commit该事务或rollback时，才会让消费端消费该消息）
发送端发送commit消息或rollback消息到消息队列之后，如果消息队列没有收到commit消息或rollback消息，那么消息队列会通过一个事务反查机制，向发送端发送事务反查消息，确定是否要把最开始的事务消息给消费端消费。

---
### kafka 触发rebalance

什么情况出发rebalance
1. 消费者组内有新消费者加入，或者有消费者退出组；
2. 订阅的主题增加了新分区；
3. 程序手动请求；

