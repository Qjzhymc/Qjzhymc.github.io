---
title: Kafka消息队列面试题
author: Yu Mengchi
categories:
  - Interview 
  - 面试知识点
  - 中间件
tags:
  - Interview
  - 消息队列
---
  
# Kafka消息队列面试题

### 为什么要使用kafka？优点？
分布式流处理平台，有效处理海量的数据

解耦、削峰、异步

### 发布订阅模型
发布订阅模型使用主题作为消息通信载体，类似于广播模式，发布者发布一条消息，该消息通过主题传递给所有的订阅者。

- Topic：topic是生产者和消费者通信的载体，生产者将消息发送到特定的topic上，消费者通过订阅特定的topic来消费消息。
- Partition：partition属于topic的一部分，一个topic可以有多个partition，并且同一topic下的partition可以分布在不同的broker上，
也就是说一个topic可以横跨多个broker。
- broker：broker可以看作是一个独立的kafka实例，多个kafka broker可以组成一个kafka 集群。

### 消息队列的重复消费、消息丢失、消息顺序等问题如何保证？


### Kafka的架构
生产者
消费者
topic
partition
broker
zookeeper

### Kafka如何保证消息的有序性

- 一个topic只指定一个partition（不现实）
- 首先在同一个partition中消息肯定是有序的，发送消息的时候指定发到哪个partition和key，kafka发送一条消息的时候，可以指定topic、partition、key、data四个参数。我们可以
把同一key的消息都发送到同一个partition中。
保证将同一个语义下消息放到同一个partition分区中，比如一个订单有支付、发货、评价三条消息，要将同一个订单的这三条消息发送到同一个分区中，保证有序性。
具体做法可以用哈希取模。

> Kafka通过分区（partition）来保证消息有序性。每个分区内的消息都是有序的，
而且Kafka保证一个分区内的消息只能被一个消费者消费。因此，如果一个主题（topic）只有一个分区，
那么消息的顺序就是有序的。如果一个主题有多个分区，那么Kafka会根据消息的key来将消息分配到不同的分区中，
保证相同key的消息被分配到同一个分区中，从而保证消息的有序性。

### 如何保证消息不丢失？
- 生产端丢失：调用send方法发送之后使用回调函数判断是否发送成功
- 消费端丢失：关闭自动提交offset，只有真正消费了之后才提交offset值。但是会带来重复消费的问题
- Kafka丢失：设置acks=all，只有全部副本都收到消息才表示发送成功，但是这样延迟会很高；设置replication.factor>=3,保证每个分区有至少3个副本，保证数据安全；
min.insync.replica>=1,代表消息至少要被写入两个副本才表示发送成功。

> 需要配置kafka使用replication，kafka 的复制机制能够让每个分区保存多个副本，在不同的broker节点上，
> 生产者发送消息到topic之后，leader partition会复制到其他从节点上，保证消息在集群内不同节点上都有副本。
> 另外，可以设置acks=all，表示只有全部副本都收到消息才表示发送成功。

### Kafka如何保证消息的唯一性？如何保证不重复消费？
- 消费消息的服务做幂等校验，比如redis的set、mysql的主键；
保证消息消费的幂等还是需要结合具体业务来实现的，比如可以让消费的消息写入redis，保证新来的消息不再redis中，也就是保证这条消息之前没有被消费过。也可以把消费的消息写入数据库，基于数据库的唯一键，保证消息不会被重复插入多条。
- 关闭自动提交enable.auto.commit设置为false，开发者在消费后手动提交。
手动提交的时候如果是消费消息后再提交，还是会出现重复消费的现象。另一种是拉取到消息后就立马提交，这种情况如果拉取到消息，提交了offset，但此时服务端挂了，重启之后就可能有消息丢失，漏消费的情况，一般在允许消息延时的场景会使用这种方式。

### Kafka出现消息堆积怎么办？
一般情况出现消息堆积要么就是生产者发送消息太快或者是消费者消费太慢。
一般会增加消费者实例数量，同时也要增加分区数量，因为一个分区只会被一个消费者消费，只增加消费者实例不增加分区只会增加空闲的消费者实例。
另外如果是生产者消息发送太快的话，可能是系统出现流量高峰，应该在上游就考虑限流降级。
如果是消费者消费太慢的话，可以看看是不是消费过程中出现了异常，

### 零拷贝技术？
传统的数据传输方式需要将数据从磁盘或内存中复制到内核缓冲区，然后再从内核缓冲区复制到用户空间缓冲区，最后
在发送到网络中。kafka使用零拷贝技术，将数据从磁盘或内存中直接传输到网络中，避免了数据复制的过程。
具体实现就是，kafka使用了操作系统的文件映射机制，将数据映射到内存中，然后通过DMA（内存直接访问）技术                                                                                 
将数据直接传输到网络中，避免了数据在内存和网络之间的多次复制。

### Kafka为什么快？
1. 零拷贝技术：使用零拷贝技术，避免了数据在内存和网络之间的多次复制，从而提高了数据传输的效率
2. 批量发送：支持批量发送消息，减少网络传输开销，提高了吞吐量
3. 分区机制：将每个主题分为多个分区，每个分区可以独立地处理消息，提高并发性能和可伸缩性
4. 集群架构：采用分布式集群架构，可以将消息存储在多个服务器上，提高系统的可用性和可靠性。

### Kafka 的leader选举过程是怎样的？
所有broker会返回自己的偏移量和元数据，使用最新的偏移量和元数据来决定新的leader。

### 什么情况会触发leader选举？
1. 当leader宕机或失效
2. 当有新的副本被添加到分区中，
3. 当分区的副本数量发生变化
4. 当broker加入或离开集群时。

### 什么是ar、isr、osr？
1. AR：每个分区指定的副本列表，包括leader和follower
2. ISR：同步副本，与leader保持同步的副本列表。
3. OSR：不同步副本：不同步副本，由于网络故障与leader失去同步的副本列表

### offset信息保持在哪里
保持在一个特殊的topic中，叫_consumer_offsets，存储了消费者组中每个消费者的分区偏移量信息，
每个偏移记录都包含了消费者组、消费者id、分区id和对应的偏移量。

### RocketMQ消息队列如何实现分布式事务？

消息队列中的事务指的是"发送端的本地事务"和"把消息发送到消息队列"这两个事件是属于同一个事务，要保证这两个操作要么都执行要么都不执行。

> 在RocketMQ中解决的方法就是使用事务消息加上事务反查机制来保证事务。发送端会发送事务消息给消息队列（事务消息也就是指half1消息，half消息暂时不会被消费端消费，会保存在另一个topic中，只有当发送端确定要commit该事务或rollback时，才会让消费端消费该消息）
发送端发送commit消息或rollback消息到消息队列之后，如果消息队列没有收到commit消息或rollback消息，那么消息队列会通过一个事务反查机制，向发送端发送事务反查消息，确定是否要把最开始的事务消息给消费端消费。



