---
title: Kafka消息队列面试题
author: Yu Mengchi
categories:
  - Interview 
  - 面试知识点
  - 中间件
tags:
  - Interview
  - 消息队列
---
  
# Kafka消息队列面试题

### 什么是Kafka？为什么要使用kafka？优点？

是一个分布式流处理平台，可以处理实时数据流，一般做消息队列使用。

为什么使用Kafka？
1. 实时数据处理：支持低延迟的消息传递；
2. 高吞吐量：能够处理大量数据，每秒可处理数百万条消息；
3. 持久性：支持数据写入磁盘，可以确保数据的持久性；
4. 扩展性：是分布式架构，容易扩展；

优点：
1. 解耦：生产者和消费者不需要直接交互，可以减少系统之间的依赖关系；更灵活、容错性高、可扩展性；
2. 削峰：流量高峰时期，Kakfa临时存储这些超额的消息，可以平滑负载，保护后端服务稳定；
3. 异步：支持异步消息传递，生产者发送消息后不用等待消费者的响应，可以提高性能。

---
### kafka快体现在哪里，为什么快？
Kafka支持高性能、低延迟的数据传输，主要是它的架构和采用的一些技术有关。
1. 零拷贝：允许数据直接从文件系统复制到网络接口，加快了数据传输速度；
2. kafka的消息支持批量发送，而且可以压缩，减小了网络开销；
3. kafka写入磁盘是顺序写，而不是随机写，减少了磁盘的寻道时间；
4. kafka一个主题可以分成多个分区，每个分区都是独立的并发单元；

---
### 为什么使用Kafka，可以直接用http调用吗？为什么要加一个Kafka？
- 解耦：生产者和消费端不需要相互依赖
- 削峰：打平高峰期的流量，消费端可以以自己的速度处理
- 异步：生产者不需要等待消费端响应，直接返回，提高响应时间和吞吐量

---
### 发布订阅模型
发布订阅模型使用主题作为消息通信载体，类似于广播模式，发布者发布一条消息，会通过主题传递给所有的订阅者。

- Topic：topic是生产者和消费者通信的载体，生产者将消息发送到特定的topic上，消费者通过订阅特定的topic来消费消息。
- Partition：partition属于topic的一部分，一个topic可以有多个partition，并且同一topic下的partition可以分布在不同的broker上，
也就是说一个topic可以横跨多个broker。
- broker：broker可以看作是一个独立的kafka实例，多个kafka broker可以组成一个kafka 集群。

---
### 消息队列的重复消费、消息丢失、消息顺序等问题如何保证？


---
### Kafka的架构是什么？包括哪些组件？各个组件的作用是什么？
1. Broker：Kafka集群就是由多个broker组成，每个kafka实例相当于就是一个broker，负责处理客户端的请求，包括生产者发布的消息和消费者订阅的消息。
2. Topic：特定主题的消息流，消息通过Topic分类管理。每个主题分成多个pattition分区，每个分区都是一个有序的消息序列；
3. Partition：主题分成多个partition分区，每个partition分区都是有序的，但是不同分区之间的有序性无法保证，每个分区都有一个Leader和多个follower；
4. Producer生产者：负责向kafka的topic主题发送消息，可以把消息发送到特定的分区，也可以让kafka决定消息放到哪个分区；
5. consumer消费者：从topic主题中拉取消息。consumer group消费者组是一组消费者的集合，共同消费一组主题的所有分区，确保每个分区只被组内的一个消费者消费。
6. zookeeper：管理集群，帮助选举leader节点、监控节点健康状态。

---
### Kafka的消息是如何被存储和传输的？
存储
1. kafka消息是按主题topic组织的，每个主题可以分成多个partition分区，每个分区是一个有序的消息序列，新的消息会不断追加到分区末尾；
2. 每个partition分区实际上是一个commit log提交日志文件，消息会追加到日志文件里；
3. partition分区支持副本，每个分区可以有多个副本分布在不同的broker上，其中有一个leader，其他的都是follower，所有的读写操作都通过leader进行，follower从leader同步数据；

传输
1. producer负责将消息发送到指定的主题，可以选择将消息发送到特定的分区；
2. consumer订阅一个或多个主题，多个consumer可以组成一个consumer group，每个consumer只处理一部分分区的消息。确保每条消息只会被同一组内的一个消费者处理；

---
### Kafka的消息保证机制有哪些？如何保证消息的可靠性？
**什么叫消息可靠性**：就是确保消息一定能发送到服务器进行存储，并且发生宕机可以从备份数据中恢复。

- 第一、生产者能否保证发送的消息是可靠的；
- 第二、消费者能够可靠的消费消息；

1. 消息可以持久化，服务器崩溃了，也可以恢复数据；
2. 副本机制:每个topic的partition分区可以配置多个副本，其中一个作为leader，其他的都是follower，leader会处理所有的读写请求，follower会从leader同步数据，如果leader失败，会进行leader选举，可以保证系统的可用性和消息的可靠性；
3. **ack机制**：生产者在发送消息的时候可以选择不同的确认级别：
- acks = 0：表示生产者不会等待消息确认，可能消息会丢失；
- acks = 1：表示生产者会等待leader确认收到消息，但是不会等待所有follower同步完成；
- acks = all：表示生产者会等待ISR列表（in-sync replicas）中的所有follower确认收到消息。
4. offset机制：kafka可以让消费者控制什么时候提交offset偏移量。消费者可以自动提交或者手动提交，手动提交可以让程序控制什么时候一条消息才叫被成功处理了，可以避免重复消费或者消息丢失；

---
### Kafka的消费者是如何工作的？如何实现消息消费的负载均衡？

消费者的工作机制：
1. 消费者可以订阅一个或多个主题来消费消息，每个主题被划分成多个partition分区，每个分区是一个有序的消息队列；
2. 消费者会以pull拉取的方式从kafka集群获取消息；
3. 消费者会记录自己的offset偏移量，下次消费的时候可以从正确的位置继续读取；
4. 消费者通常以消费者组的形式工作，同一个消费者组内的消费者共同消费一个主题的消息，每个分区只能由组内一个消费者消费。

消息消费的负载均衡：
1. kafka的主题会划分成多个分区，在同一个消费者组里面，会把分区分配给不同的消费者，分区分配的目标是尽量让每个消费者处理相同数量的分区；
2. kafka有一些分区分配的策略，比如按范围分配，轮询分配，粘性分配（在保证均匀的同时，尽量减少分区重新分配的次数）
3. 动态再平衡：当消费者组内的消费者数量发生变化时，比如新增或移除消费者，kafka会触发再平衡操作
4. 一个分区只能给组内一个消费者消费；一个消费者可以消费多个分区。不同组的就互不影响

---
### Kafka的生产者是如何发送消息的？如何实现消息的批量发送？

发送消息流程：
1. 创建消息：包含key，value，topic，key用于分区选择，value是消息内容；
2. 分区选择：根据消息的key、分区策略或用户指定的分区号，选择消息要发送到的目标分区
3. 批量缓存：生产者会把消息缓存在内存中batch里，每个batch对应一个分区；
4. 发送请求：当batch.size满了，或者手动触发强制发送，会将所有batch打包成一个请求，发送到broker节点
5. 确认机制：生产者会有ack确认机制，决定消失是否发送成功
6. 重试机制：如果失败了，还会有重试机制。

如何实现消息的批量发送：
1. kafka会将多条消息打包成一个batch，一个batch对应一个分区，然后一次性发送给broker。
2. 批量发送的触发条件，批量的batch达到一定的条件就会一次性发送给broker，比如批次大小达到了batch.size大小、或者等待时间超时了、或者手动调用flush()强制发送。

### consumer怎么消费partition的？
Consumer是通过pull()方法拉取partition的消息的。指定topic和partition，broker返回一批数据。

consumer处理完消息后，调用commit提交消息offset值。消费者也可以指定offset值。

---
### Kafka的消息大小有限制吗？如何处理大消息？

有，默认是1MB，参数是max.request.size

如何处理大消息：
1. 修改配置
- 修改broker的配置，leader和follower之间同步消息的最大配置；
- 修改producer的配置，修改发送端的最大发送配置；
- 修改consumer的配置，修改消费者拉取消息的最大拉取配置；
2. 拆分大消息
- 在生产者端拆分成多个小消息；
- 使用分区键确保所有消息都发送到同一个分区，保证顺序性；
- 在消费者端根据分区键将小消息重新组成成完整的大消息；
3. 存储大消息的引用
- 把大消息存储在外部系统，比如HDFS或数据库
- 将指向外部存储系统的引用作为消息发送；
- 消费时收到引用，读取实际数据。
4. 启动压缩：生产者端可以启动压缩

---
### Kafka的消费者如何处理重复消息？如何保证消息的有序性？

为什么会收到重复消息？
1. 消费者组有消费者加入或退出，分区会被重新分配，可能导致重复消费；
2. offset没有成功提交；

避免重复消息解决方法：
1. 幂等性设计：确保消费者的业务逻辑是幂等性的，同一条消息被多次处理也不会产生副作用。比如可以通过数据库的唯一键约束避免重复操作；
2. Exactly once语义：使用kafka的事务功能，确保生产者和消费者之间的消息传递是exactly once精确一次的
3. 手动管理offset：消费者手动控制offset的提交时机，确保只有消息成功处理完成后才提交offset值。

如何保证消息有序性：
1. **分区键**：把同一业务逻辑的消息用相同的分区键路由到同一个分区，保证相对有序
2. **单分区**：如果需要所有消息都有序，可以将所有消息都写到同一个分区。会牺牲吞吐量。
3. **消费者单线程处理**：每个分区只能由一个消费者线程处理，避免多线程并发处理导致乱序。
4. **手动提交offset**：确保消息按顺序处理完成后再提交偏移量

---
### Kafka partition数量和consumer数量有什么关系，消费者组是什么作用？

一个partition可以被多个消费者组消费，但是在一个消费组内只能有一个消费者消费。

**消费者组的作用：**
- 消费者组会协调消费者，确保每个消息仅由一个消费者消费。当新的消费者加入或现有消费者离开时，消费者组会重新分配分区
  确保负载均衡。
- 使用消费者组可以让一个分区被不同的消费者组消费，能并行消费消息，每个消费者组处理
  一部分消息，提高性能和吞吐量。

---
### 3个partition，两个consumer怎么消费
1. range assignor(range分配)：对分区排序，然后将连续的一批分区分给对应的消费者
2. 轮询分配：轮流分配给消费者

---
### Kafka的消息格式是什么？如何实现自定义消息格式？

kafka会把多条消息放在一个batch里，batch里面是一个个record，一个record就是一条消息，
record里面有：
1. key：用于分区分配
2. value：消息的实际内容
3. Headers：是一组键值对，用来存储一些和消息相关的上下文信息，比如时间戳、来源系统名字等
4. timestamp：每条消息都有一个timestamp，表示消息的生产时间
5. offset值：表示消息在分区中的位置
6. partition：可以指定放在哪个partition分区

---
### Kafka的分区机制是什么？如何实现分区的负载均衡？

分区机制就是指kafka中的每个topic主题会被划分成多个partition分区，每个分区是一个有序的消息队列，分区允许kafka在多个broker之间分布数据。

分区作用：
- 可以提交吞吐量，把数据分散到多个分区中，
- 水平扩展：可以增加分区数量扩展存储能力
- 容错性：每个分区有多个副本，可以提交容错性

如何实现分区的负载均衡：
- 生产者：有分区分配策略：比如轮询分配分区、按键值计算分区
- 消费者：同一个主题的所有消费者会组成一个消费者组，共同消费一个主题的所有分区，kafka会确保每个分区只被组内的一个消费者消费，避免重复消费，消费者数量增加或减少时会有再平衡机制，重新分配分区
- broker的负载均衡：kafka会尽量将分区均匀分布在集群中所有的broker上，每个分区都有一个leader和多个follower，kafka会动态调整leader和follower的角色，确保负载均衡。

---
### Kafka的副本机制是什么？如何实现副本的同步和选举？

一个主题会有多个分区，分区中有一个leader和多个follower，每个分区都会有一个leader副本，follower副本会从leader副本同步数据。

**副本集合**
- AR：assigned replicas 分配给分区的所有副本集合
- ISR：in-sync replicas 与leader保持同步的副本集合，包括leader本身和保持同步的follower
- OSR：out-of-sync replicas 没有与leader保持同步的副本集合

选举过程：
1. 故障检测：kafka的控制器会监控broker的状态，如果发现leader副本可以用，会触发选举
2. 选择新leader：优先从ISR列表中选择一个新的leader，如果ISR列表为空，则从OSR中选择一个副本
3. 更新元数据：新的leader信息会被更新到zookeeper，其他broker和消费者会感知到leader的变更。

---
### Kafka的高可用性是什么？如何保障Kafka的高可用性？

1. 副本机制：kafka为每个主题设置多个副本，副本分布在不同的broker上，每个分区都有一个leader和多个follower。生产者发送的消息首先发给leader，然后同步给follower；
2. ack机制：生产者可以控制消息的确认级别，避免数据丢失
3. 故障恢复机制：当leader所在的broker节点宕机时，kafka会从ISR列表中选举一个新的leader继续提供服务
4. offset管理：消费者可以手动提交消费进度，这样的话消费者故障重启后也不会重复消费数据或者丢失已经消费的数据

---
### Kafka的应用场景有哪些？如何根据不同场景使用Kafka？

1. 消息队列：解耦生产者和消费者，解耦、削峰、异步；
2. 日志聚合：收集日志数据，集中管理和分析；
3. 流处理：对实时数据流进行处理，比如过滤、聚合、转换。

---
### Kafka和其他消息队列的比较有哪些？Kafka的优势在哪里？

Kafka的特性：
1. 支持持久化数据到磁盘
2. 支持消费者组的概念，同一个组内的消费者不会重复消费相同的消息
3. 支持扩展，可以通过添加节点增加吞吐量和存储容量

优势：
1. 超高吞吐量
2. 持久化存储
3. 分布式架构
4. 实时处理能力
5. 灵活的消费模型：通过消费者组实现高效的消息负载均衡
6. 强大的生态系统：有很多客户端库、框架以及与大数据生态系统的良好集成。

---
### Kafka如何保证消息的有序性

- 一个topic只指定一个partition（不现实）
- 首先在同一个partition中消息肯定是有序的，发送消息的时候可以根据key指定发到哪个partition，kafka发送一条消息的时候，可以指定topic、partition、key、data四个参数。我们可以
把同一key的消息都发送到同一个partition中。
保证将同一个语义下的消息放到同一个partition分区中，比如一个订单有支付、发货、评价三条消息，要将同一个订单的这三条消息发送到同一个分区中，保证有序性。
具体做法可以用哈希取模。

> Kafka通过分区（partition）来保证消息有序性。每个分区内的消息都是有序的，
而且Kafka保证一个分区内的消息只能被一个消费者消费。因此，如果一个主题（topic）只有一个分区，
那么消息的顺序就是有序的。如果一个主题有多个分区，那么Kafka会根据消息的key来将消息分配到不同的分区中，
保证相同key的消息被分配到同一个分区中，从而保证消息的有序性。

---
### 如何保证消息不丢失？
- 生产端丢失：调用send方法发送之后使用回调函数判断是否发送成功
- 消费端丢失：关闭自动提交offset，只有真正消费了之后才提交offset值。但是会带来重复消费的问题
- Kafka丢失：设置acks=all，只有全部副本都收到消息才表示发送成功，但是这样延迟会很高；设置replication.factor>=3,保证每个分区有至少3个副本，保证数据安全；
min.insync.replica>=1,代表消息至少要被写入两个副本才表示发送成功。

> 需要配置kafka使用replication，kafka 的复制机制能够让每个分区保存多个副本，在不同的broker节点上，
> 生产者发送消息到topic之后，分区的主节点会把消息复制到其他从节点上，保证消息在集群内不同节点上都有副本。
> 另外，可以设置acks=all，表示只有全部副本都收到消息才表示发送成功。

---
### Kafka如何保证消息的唯一性？如何保证不重复消费？
- 消费消息的服务做幂等校验，比如redis的set、mysql的主键；
保证消息消费的幂等还是需要结合具体业务来实现的，比如可以让消费的消息写入redis，保证新来的消息不在redis中，也就是保证这条消息之前没有被消费过。也可以把消费的消息写入数据库，基于数据库的唯一键，保证消息不会被重复插入多条。
- 关闭自动提交enable.auto.commit设置为false，开发者在消费后手动提交。
手动提交的时候如果是消费消息后再提交，还是会出现重复消费的现象。另一种是拉取到消息后就立马提交，这种情况如果拉取到消息，提交了offset，但此时服务端挂了，重启之后就可能有消息丢失，漏消费的情况，一般在允许消息延时的场景会使用这种方式。

---
### Kafka出现消息堆积怎么办？
- 一般情况出现消息堆积要么就是生产者发送消息太快或者是消费者消费太慢。
- 一般会增加消费者实例数量，同时也要增加分区数量，因为一个分区只会被一个消费者消费，只增加消费者实例不增加分区只会增加空闲的消费者实例。
另外如果是生产者消息发送太快的话，可能是系统出现流量高峰，应该在上游就考虑限流降级。
如果是消费者消费太慢的话，可以看看是不是消费过程中出现了异常。

---
### 怎么解决线上消息队列积压问题

---
### 消息队列有处理过发生延迟的情况吗？
会有，一般是网络问题或者是流量高峰的时候会出现。

- 首先我们会配置消息堆积量的告警，出现不同程度的堆积情况会有相应级别的告警；
- 消息队列客户端消费消息的话一般通过长轮训批量拉取消息，然后提交给消费线程。
- 如果出现消息堆积通常是客户端的消费能力跟不上，消息消费耗时比较长，或者是消费并发度不够。
- 首先优先解决消费耗时的问题，把消费耗时控制在合理的范围，比如如果有外部的IO操作，读写数据库、读写缓存、或者下游RPC调用或HTTP调用，都可能导致消费耗时增加，可以尝试本地缓存一些需要的数据。
- 可以扩大Topic分区数，扩大单个节点的并发线程数。

> 反正就是从消费耗时和并发度的角度优化吧。

如何处理:
- 查看是客户端还是服务端发生的堆积，查看客户端的堆栈信息，一般是网络问题、或者外部数据库读写问题。
- 如果堆积的消息可以跳过不消费的话，可以重置消费位点跳过这些堆积的消息从最新位点开始消费。

---
### 零拷贝技术？
传统的数据传输方式需要将数据从磁盘或内存中复制到内核缓冲区，然后再从内核缓冲区复制到用户空间缓冲区，最后
再发送到网络中。
> kafka使用零拷贝技术，将数据从磁盘或内存中直接传输到网络中，避免了数据复制的过程。
具体实现就是，kafka使用了操作系统的文件映射机制，将数据映射到内存中，然后通过DMA（内存直接访问）技术                                                                                 
将数据直接传输到网络中，避免了数据在内存和网络之间的多次复制。

---
### Kafka为什么快？
1. 零拷贝技术：使用零拷贝技术，避免了数据在内存和网络之间的多次复制，提高了数据传输的效率
2. 批量发送：支持批量发送消息，减少网络传输开销，提高了吞吐量
3. 分区机制：将每个主题分为多个分区，每个分区可以独立地处理消息，提高并发性能和可伸缩性
4. 集群架构：采用分布式集群架构，可以将消息存储在多个服务器上，提高系统的可用性和可靠性。

---
### Kafka 的leader选举过程是怎样的？
所有broker会返回自己的偏移量和元数据，使用最新的偏移量和元数据来决定新的leader。

---
### 什么情况会触发leader选举？
1. 当leader宕机或失效
2. 当有新的副本被添加到分区中
3. 当分区的副本数量发生变化
4. 当broker加入或离开集群时。

---
### 什么是ar、isr、osr？
1. AR：每个分区指定的副本列表，包括leader和follower
2. ISR：同步副本，与leader保持同步的副本列表。
3. OSR：不同步副本，由于网络故障与leader失去同步的副本列表

---
### Kafka的offset是什么？如何管理和维护offset？

offset解决了以下问题：
1. 消费进度跟踪：记录每个分区消费到哪个位置；
2. 消费可靠性保证：确保消息不丢失，不重复处理
3. 消费者故障恢复：消费者重启后可从上次位置继续消费

offset存储演变：
1. 早期版本(<0.9):offset存储在Zookeeper中
2. 现代版本(>=0.9):offset存储在内部主题__consumer_offsets中

offset提交方式：
1. 自动提交：
 - 由消费者客户端自动定期提交当前位移
 - 由enable.auto.commit和auto.commit.interval.ms控制
2. 手动提交
 - 同步提交(commitSync):阻塞直到提交成功或失败
 - 异步提交(commitAsync):非阻塞，可提供回调处理结果


实现Exactly-Once语义：
1. 手动offset控制：禁用自动提交
2. 事务性输出：输出端支持事务或幂等操作
3. 原子提交：将处理结果和位移在一个事务中提交

---
### offset信息保存在哪里
保存在一个特殊的topic中，叫_consumer_offsets，存储了消费者组中每个消费者的分区偏移量信息，
每个偏移记录都包含了消费者组、消费者id、分区id和对应的偏移量。

---
### RocketMQ消息队列如何实现分布式事务？

消息队列中的事务指的是"发送端的本地事务"和"把消息发送到消息队列"这两个事件是属于同一个事务，要保证这两个操作要么都执行要么都不执行。

> 在RocketMQ中解决的方法就是使用事务消息加上事务反查机制来保证事务。发送端会发送事务消息给消息队列（事务消息也就是指half消息，half消息暂时不会被消费端消费，会保存在另一个topic中，只有当发送端确定要commit该事务或rollback时，才会让消费端消费该消息）
发送端发送commit消息或rollback消息到消息队列之后，如果消息队列没有收到commit消息或rollback消息，那么消息队列会通过一个事务反查机制，向发送端发送事务反查消息，确定是否要把最开始的事务消息给消费端消费。

---
### kafka 触发rebalance

Rebalance是kafka用于在消费者组内成员增加或删除的时候重新分配分区的机制。

什么情况触发rebalance
1. 消费者组内有新消费者加入，或者有消费者退出组；
2. 订阅的主题增加了新分区；
3. 程序手动请求；

rebalance过程：
1. PreparingRebalance状态：所有消费者停止消费；
2. 组成员加入请求(JoinGroup):消费者向Coordinator发送加入请求；
3. 选举消费者组长：通常是第一个加入的消费者
4. 分区分配：组长运行分区分配算法
5. 同步分配方案(SyncGroup):Coordinator将分配方案发送给所有成员
6. 恢复消费：消费者根据分配结果开始消费

rebalance主要问题：
1. 消费停滞：rebalance期间整个消费者组停止消费；
2. 重复处理：rebalance后可能重复消费部分消息
3. 频繁再平衡：导致"再平衡风暴"，严重影响吞吐量

优化策略：
1. 调整session.timeout.ms:默认10s，增大可减少因临时网络问题导致的再平衡；
2. 调整heartbeat.intervals.ms：默认3s，应设为timeout的1/3
3. 调整max.poll.interval.ms:默认5分钟，增大可适应处理时间较长的场景
4. 使用Sticky分配策略：尽量保留现有分配，减少分区转移

---
### Kafka落盘如何建立索引
一个topic有多个partition，一个partition由多个segment组成，
一个segment对应两个文件，一个.index文件和一个.log文件组成
1. index索引文件里存放log数据文件里的每一条消息的物理偏移地址
2. log数据文件里是一条条消息

> partition里的第一个segment从0开始，后续每组segment里的index文件和log文件名称相同，表示上一个segment最后一条消息的offset值。

> 一个partition分成多个小文件段，可以方便清除已经消费的数据，减少磁盘占用。

---
### 什么是消费者组？解决了什么问题？工作原理是什么？
允许多个消费者实例并行消费同一个主题的消息。

作用：
1. 扩展消费能力，提高消费者实例数量，提高吞吐量
2. 负载均衡：自动将分区分配给组内的消费者，实现工作负载均衡
3. 容错机制：当消费者宕机时，自动重新分配分区给其他消费者；

核心架构和概念：
1. GroupID：每个消费者组都有一个唯一的组ID
2. 分区分配：每个分区在一个消费组内只能被一个消费者消费
3. rebalance：在消费者加入或离开时自动重新分配分区

关键机制：
1. Group Coordinator：一个特殊的broker，负责管理消费者组
2. 心跳机制：消费者定期向Coordinator发送心跳，表明自己活跃
3. 分区分配策略：包括range，RoundRobin，Sticky等多种策略
4. 提交位移Offset：记录消费进度的机制

分区分配策略：
1. RangeAssignor：按分区范围划分给消费者
2. RoundRobinAssignor：将所有分区轮询分配给消费者
3. StickyAssignor:在满足均衡的前提下，尽量维持原有分配

Group Coordinator作用是什么：
1. 成员管理：处理消费者加入或离开请求
2. 状态维护：跟踪消费者组状态和成员信息
3. 再平衡协调：触发和管理再平衡过程
4. 位移管理：管理__consumer_offsets主题中的提交记录

消费者组有哪些状态：
1. Empty：表示组内没有活跃的消费者
2. Dead：组内没有消费者，并且组元数据已被删除
3. PreparingRebalance(准备再平衡)：等待现有成员加入再平衡过程
4. CompletingRebalance(完成再平衡)：组长已计算分配方案，等待所有成员接收
5. Stable(稳定)：再平衡完成，所有消费者正常工作。
