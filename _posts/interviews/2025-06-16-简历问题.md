---
title: 简历问题
author: Yu Mengchi
categories:
  - Interview
  - 面试知识点
tags:
  - Interview
---

---
### 什么是oCPX广告？
Yes, I am familiar with OCPX advertising.
OCPX stands for "Optimized Cost Per Click," which is a type of advertising model that uses machine learning algorithms to optimize the cost per click of an ad campaign.
With OCPX, the advertiser sets a target cost per click, and the algorithm automatically adjusts the bid for each ad placement based on the likelihood of a click and the value of that click to the advertiser.
This helps to maximize the return on investment (ROI) of the ad campaign and improve the overall performance of the advertising strategy.

oCPX广告是广告的一个新的投放模式，广告出价机制。
- 传统的结算模式，比如CPC是按点击付费、CPD按下载付费、CPM按千次曝光付费，这些都是传统的付费方式。
- 但是oCPX是加入了广告平台方的数据和算法能力，可以对转化目标进行优化。广告主会设定转化目标和目标成本。系统会根据转化效果，利用算法自动调整出价

可以更好的优化广告的效果和成本。

eCPM=BID*pCTR*pCVR*1000   千次展示获得收入 = 出价 * 点击概率 * 转化概率 * 1000

---
### oCPX广告配置服务干嘛的?pid调价服务干嘛的？广告归因服务干嘛的？
广告配置主要做广告的配置管理，比如广告主目标出价、转化目标，还包括一些定时任务的管理，比如二阶判断。

pid调价服务，会判断实时的转化成本，和广告主设置的目标成本。智能调价:当实际转化成本高于目标转化成本时，系统会降低出价，反之则会提高出价。

广告归因服务，把广告带来的转化行为流，归因到具体的广告上，就是分析是哪个广告带来的转化。

---
### 做了哪些重构工作?有哪些问题？怎么解决的？

1. 分布式改造：服务里有很多定时任务，是单线程的，现在需要改成分布式的，我们抽象出了接口，由外部服务定时路由到实例上执行。
2. 底层数据改造：数据纵向分表，表拆分，按维度将宽表拆分。
3. 本地缓存，广告数据的本地缓存。

---
### 广告分发链路是怎样的？
1. 用户发起广告检索请求
2. 根据用户信息、用户历史行为召回备选广告
3. 粗排
4. 精排
5. 过滤、排序
6. 展示
7. 收集转化数据

---
### 游戏、打点激活调价服务需求是什么？怎么做的？

游戏、打点激活是一种广告的转化目标，在整个广告链路中新增一种转化类型，需要把调价维度加上这些新的转化目标。

1. 调价需要设定目标成本，这个是调价目标；
2. 然后根据广告的实际表现，比如不同维度的转化数据。
3. 利用pid算法调整合适的出价

pid算法：
1. p：比例单元
2. i：积分单元
3. d：微分单元

---
### 流量优选、人群自动定向数据流是什么需求，如何开发的？如何精细化利用流量？

流量优选:新增一条数据流，统计当日广告的转化数据。读取计费数据流，统计广告在每天的指标的聚合，比如付费、下载数量、点击数、(不同目标的)转化数，然后写入redis上，由算法和调价服务使用。

人群自动扩量：新增一条数据流，聚合当日付费、当日目标出价、当日目标pdeepdvr、当日目标转化数等指标

---
### 倒排索引

---
### 数据看板怎么开发的？如何使用spark的，如何使用flink的？
1. 确定数据源，是hive表，判断是否生成_success文件，判断前一日的数据是否完成；
2. Spark进行数据清洗，统计计算 统计、聚合、筛选。
3. 聚合后的数据导出到mysql表中，存储分析结果
4. 在看板上连接mysql表，配置指标和维度。生成看板。

---
### CICD平台如何设计的？
gitlab：代码管理平台
jenkins：CI/CD平台
k8s：容器编排平台
docker：容器镜像管理平台

---
### 导调控制模块、GIS地图模块、试验验证方案管理、红蓝军对抗仿真验证模块都是什么？


---
### 定制化了哪些任务类型？
1. 区域关联、多分支、覆盖重数、定时快照、原始表同步(datax,canal)、

---
### DataX如何使用的？什么原理？
1. 根据配置信息，同步表名、同步字段名、源和目标数据库
2. 在执行器的jobHandler内生成json文件。生成Reader和Writer部分
3. 执行datax的python命令，执行datax同步任务

DataX架构：
1. Reader：有很多种类型的Reader插件
2. framework：会切分任务，调度，在线程池内执行
3. Writer：

---
### Canal如何使用的？什么原理？
是阿里开源的一款基于Mysql数据库binlog的增量数据同步的中间件，
可以订阅binlog日志，然后进行一些数据消费。

1. canal模拟mysql slave与mysql master的交互协议，伪装自己是一个mysql slave，向mysql master发送dump协议；
2. mysql master收到mysql slave（canal）发送的dump请求，开始推送binlog增量日志给slave(也就是canal)；
3. mysql slave（canal伪装的）收到binlog增量日志后,就可以对这部分日志进行解析，获取主库的结构及数据变更；

mysql主从同步原理：

---
### xxl-job和DolphinScheduler有啥区别？怎么开发Task插件和Dao插件的？
dolphin有DAG，可以配置任务流，有依赖关系。

基于SPI机制开发插件

---
### 怎么开发text2Sql功能？
1. 基于提示词工程，给定prompt，比如你是一个sql生成专家，给定表结构，只需要给出sql语句，不需要解释。

LLama
Qwen
DeepSeek

SSE：Server-Sent Event。基于Http协议，服务器可以持续发送数据给客户端。context-type=text/event-stream,

模型部署在OLLama上，后端使用SpringAI读取Ollama上部署的模型，然后前端发送请求，后端调用模型，发送SSE消息给前端。


```java
@SpringBootTest
class SpringAiApplicationTests {
  @Autowired
  private OllamaChatClient chatClient;

  @Test
  void contextLoads() {
    String message = "鲁迅和周树人什么关系";
    System.out.println(chatClient.call(message));
  }

  //流式访问
  void streamChat() throws ExecutionException, InterruptedException {
    CompletableFuture<Void> future = new CompletableFuture<>();

    String message = "xxx";
    PromptTemplate promptTemplate = new PromptTemplate("xxx");

    Prompt prompt = promptTemplate.create(Map.of("message", message));
    chatClient.stream(prompt).subscribe(
      chatResponse -> {
        System.out.println("response: " + chatResponse.getResult().getOutput().getContent());

      },
      throwable -> {
        System.err.println("err:" + throwable.getMessage());
      },
      () -> {
        System.out.println("complete");
        future.complete(null);
      }
    );
    future.get();
  }
}

```

```java
@RestController
public class SseController {

    private final List<SseEmitter> emitters = new CopyOnWriteArrayList<>();
    private final ExecutorService executor = Executors.newCachedThreadPool();
    private final AtomicLong counter = new AtomicLong();

    @GetMapping("/sse")
    public SseEmitter sse() {
        SseEmitter emitter = new SseEmitter(-1L); // -1 表示不设置超时
        emitters.add(emitter);

        emitter.onCompletion(() -> emitters.remove(emitter));
        emitter.onTimeout(() -> emitters.remove(emitter));
        emitter.onError((e) -> emitters.remove(emitter));

        // 可选：发送一个初始消息
        try {
            emitter.send(SseEmitter.event().name("INIT").data("连接已建立"));
        } catch (IOException e) {
            emitter.completeWithError(e);
        }
        return emitter;
    }

    // 模拟推送消息的示例方法
    public void pushMessage(String message) {
        for (SseEmitter emitter : emitters) {
            executor.execute(() -> {
                try {
                    emitter.send(SseEmitter.event().name("message").data(message));
                } catch (IOException e) {
                    emitter.completeWithError(e);
                }
            });
        }
    }

    // 模拟定时推送消息
    @GetMapping("/start-pushing")
    public String startPushing() {
        executor.execute(() -> {
            while (true) {
                try {
                    Thread.sleep(2000); // 每2秒推送一次
                    pushMessage("服务器推送的消息 " + counter.incrementAndGet());
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                    break;
                }
            }
        });
        return "开始推送消息";
    }

    // 停止推送消息
    @GetMapping("/stop-pushing")
    public String stopPushing() {
        executor.shutdownNow();
        return "停止推送消息";
    }
}
```

---
### SEIR模型是什么？
是预测传染病传播动态的数学模型，会把人群划分成不同的种类：
S：表示Susceptible，易感者，没有感染但有可能感染的人群
E：表示暴露者，已经感染，处于潜伏期的人群
I：表示感染者，已经感染
R：表示恢复着。

SEIR模型会通过一组微分方程来描述这四类人群随时间变化的趋势。我们这个推演模型就是根据这个模型，计算这四种人群在推演过程中的数量变化。

---
### Socket IO是什么？
可以在浏览器和后端服务器实现实时、双向通信的一个工具。
传输层可以基于HTTP长轮训，也可以基于Websocket。会监听客户端连接。可以广播，也可以创建不同房间，向单个房间发送消息。


---
### Kettle是什么？如何实现的？用了哪些设计模式？

1. 构建工作流Dag图，工厂模式创建不同类型的节点。用了邻接表来表示一个DAG图
2. 用策略模式支持不同类型的任务，每种任务可以继承 
3. 然后通过一个调度器，按照依赖顺序依次执行节点，每个节点输出作为下一个节点的输入， 
4. 通过todoTask，执行完了todo任务，在执行后续节点，用责任链模式把数据传给下一个节点。

在这个项目中，我实现了一个 DAG 引擎用于调度 ETL 任务。主要应用了以下几种设计模式：




