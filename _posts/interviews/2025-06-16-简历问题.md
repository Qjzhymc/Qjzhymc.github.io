---
title: 简历问题
author: Yu Mengchi
categories:
  - Interview
  - 面试知识点
tags:
  - Interview
---

---
### 什么是oCPX广告？
Yes, I am familiar with OCPX advertising.
OCPX stands for "Optimized Cost Per Click," which is a type of advertising model that uses machine learning algorithms to optimize the cost per click of an ad campaign.
With OCPX, the advertiser sets a target cost per click, and the algorithm automatically adjusts the bid for each ad placement based on the likelihood of a click and the value of that click to the advertiser.
This helps to maximize the return on investment (ROI) of the ad campaign and improve the overall performance of the advertising strategy.

oCPX广告是广告的一个新的投放模式，广告出价机制。
- 传统的结算模式，比如CPC是按点击付费、CPD按下载付费、CPM按千次曝光付费，这些都是传统的付费方式。
- 但是oCPX是加入了广告平台方的数据和算法能力，可以对转化目标进行优化。广告主会设定转化目标和目标成本。系统会根据转化效果，利用算法自动调整出价

可以更好的优化广告的效果和成本。

eCPM=BID*pCTR*pCVR*1000   千次展示获得收入 = 出价 * 点击概率 * 转化概率 * 1000

---
### oCPX广告配置服务干嘛的?pid调价服务干嘛的？广告归因服务干嘛的？
广告配置主要做广告的配置管理，比如广告主目标出价、转化目标，还包括一些定时任务的管理，比如二阶判断。

pid调价服务，会判断实时的转化成本，和广告主设置的目标成本。智能调价:当实际转化成本高于目标转化成本时，系统会降低出价，反之则会提高出价。

广告归因服务，把广告带来的转化行为流，归因到具体的广告上，就是分析是哪个广告带来的转化。

---
### 做了哪些重构工作?有哪些问题？怎么解决的？

1. 分布式改造：服务里有很多定时任务，是单线程的，现在需要改成分布式的，我们抽象出了接口，由外部服务定时路由到实例上执行。
2. 底层数据改造：数据垂直分表，表拆分，按维度将宽表拆分。
3. 本地缓存，广告数据的本地缓存。

---
### 广告分发链路是怎样的？
1. 用户发起广告检索请求
2. 根据用户信息、用户历史行为召回备选广告
3. 粗排
4. 精排
5. 过滤、排序
6. 展示
7. 收集转化数据

---
### 游戏、打点激活调价服务需求是什么？怎么做的？
游戏、打点激活是一种广告的转化目标，在整个广告链路中新增一种转化类型，需要把调价维度加上这些新的转化目标。

1. 调价需要设定目标成本，这个是调价目标；
2. 然后根据广告的实际表现，比如不同维度的转化数据。
3. 利用pid算法调整合适的出价

pid算法：
1. p：比例单元
2. i：积分单元
3. d：微分单元

---
### 流量优选、人群自动定向数据流是什么需求，如何开发的？如何精细化利用流量？

流量优选:新增一条数据流，统计当日广告的转化数据。读取计费数据流，统计广告在每天的指标的聚合，比如付费、下载数量、点击数、(不同目标的)转化数，然后写入redis上，由算法和调价服务使用。

人群自动扩量：新增一条数据流，聚合当日付费、当日目标出价、当日目标pdeepdcvr、当日目标转化数等指标

---
### 超成本、欠成本、OCPM赔付
系统需要通过算法预估和动态调价，让"实际转化成本"围绕广告主设定的"目标成本"上下波动，但是在冷启动阶段，模型数据少、转化数据回传延迟等问题，导致波动
1. 超成本：实际转化成本>广告主设定的目标成本。
- 对于广告主：预算浪费、ROI暴跌，尤其对中小商家致命
- 模型数据少导致平台算法预估偏差
2. 欠成本：实际转化成本小于目标成本
- 对于平台：优质流量被贱卖，挤压平台利润空间
3. OCPM赔付：广告平台为了减弱广告主投放时对超成本的顾虑，同时为模型波动等问题进行兜底，平台对广告投放前14天，当超成本率大于20%时，对超出成本的部分进行赔付

---
### 混排
比如在信息流推荐场景下，推荐系统会返回一个推荐列表，广告系统会返回一个广告列表，需要综合考虑推荐和广告的组合结果。

---
### 明投和暗投
主要区别在于广告主对投放渠道的控制程度；

明投是由广告主通过广告平台自主选择投放渠道，指定广告展示的媒体或关键词展示广告；

暗投是由广告平台选择投放渠道，广告主无法完全掌控实际投放渠道，需要依赖平台的流量分配机制。

---
### 倒排索引

---
### 数据看板怎么开发的？如何使用spark的，如何使用flink的？
1. 确定数据源，是hive表，判断是否生成_success文件，判断前一日的数据是否完成；
2. Spark进行数据清洗，统计计算。统计、聚合、筛选。
3. 聚合后的数据导出到mysql表中，存储分析结果
4. 在看板上连接mysql表，配置指标和维度。生成看板。

---
### CICD平台如何设计的？
gitlab：代码管理平台
jenkins：CI/CD平台
k8s：容器编排平台
docker：容器镜像管理平台

---
### 导调控制模块、GIS地图模块、试验验证方案管理、红蓝军对抗仿真验证模块都是什么？


---
### 定制化了哪些任务类型？
1. 区域关联、多分支、覆盖重数、定时快照、原始表同步(datax,canal)

---
### DataX如何使用的？什么原理？
1. 根据配置信息，同步表名、同步字段名、源和目标数据库
2. 在执行器的jobHandler内生成json文件。生成Reader和Writer部分
3. 执行datax的python命令，执行datax同步任务

DataX架构：
1. Reader：有很多种类型的Reader插件
2. framework：会切分任务，调度，在线程池内执行
3. Writer：

---
### 基于DataX做离线数据同步，如何保证时效性、一致性？
首先DataX主要还是用于对存量的数据做离线的同步，更多的还是用于数据备份或者离线计算的场景。
如果需要做完存量同步之后，再同步增量数据，就需要借助其他调度工具以固定频率触发增量任务。
比如可以用linux自带的crontab调度能力或者xxl-job这种工具，一天同步一次，但还是做不到实时或近实时。
而且dataX的job执行还需要源表字段里有自增id或者时间戳这种字段，才能用where筛选出来增量数据。在dataX的job里where条件里通过时间戳筛选。
还有dataX的同步是基于select查询数据的，如果在源表里对之前已同步数据做了update修改，dataX没法筛选出来同步到目标表。

---
### 基于Canal做实时数据同步，如何保证时效性、一致性？
canal本身就是基于监听mysql binlog实现的，所以源表有insert、update、delete事件的变化canal客户端都能监听到。
如果需要处理网络延迟、重复同步等异常的话，可以通过数据库唯一索引保证重复消费时的幂等性；也可以在写入数据时记录写入失败的记录稍后重试；或者再添加数据对账机制，每天全量按主键比对保证一致性。

---
### Canal如何使用的？什么原理？
是阿里开源的一款基于监听Mysql binlog的增量数据同步的中间件，可以订阅binlog日志，然后进行一些数据消费。

如何使用：
1. mysql修改my.cnf配置文件启动binlog
2. 创建canal用户，在canal的配置文件中配置监听数据库，启动canal实例
3. 代码中使用canal客户端，订阅binlog日志，判断row类型，是insert还是update还是delete，处理对应的逻辑。

原理：
1. canal模拟mysql slave与mysql master的交互协议，伪装自己是一个mysql slave，向mysql master发送dump协议；
2. mysql master收到mysql slave（canal）发送的dump请求，开始推送binlog增量日志给slave(也就是canal)；
3. mysql slave（canal伪装的）收到binlog增量日志后,就可以对这部分日志进行解析，获取主库的结构及数据变更；

---
### xxl-job和DolphinScheduler有啥区别？怎么开发Task插件和Dao插件的？
dolphin有DAG，可以配置任务流，有依赖关系。

基于SPI机制开发插件

---
### 怎么开发text2Sql功能？
1. 基于提示词工程，给定prompt，比如你是一个sql生成专家，给定表结构，只需要给出sql语句，不需要解释。

SSE：Server-Sent Event。基于Http协议，服务器可以持续发送数据给客户端。context-type=text/event-stream,

模型部署在OLLama上，后端使用SpringAI读取Ollama上部署的模型，然后前端发送请求，后端调用模型，发送SSE消息给前端。

```java
@SpringBootTest
class SpringAiApplicationTests {
  @Autowired
  private OllamaChatClient chatClient;

  @Test
  void contextLoads() {
    String message = "鲁迅和周树人什么关系";
    System.out.println(chatClient.call(message));
  }

  //流式访问
  void streamChat() throws ExecutionException, InterruptedException {
    CompletableFuture<Void> future = new CompletableFuture<>();

    String message = "xxx";
    PromptTemplate promptTemplate = new PromptTemplate("xxx");

    Prompt prompt = promptTemplate.create(Map.of("message", message));
    chatClient.stream(prompt).subscribe(
      chatResponse -> {
        System.out.println("response: " + chatResponse.getResult().getOutput().getContent());

      },
      throwable -> {
        System.err.println("err:" + throwable.getMessage());
      },
      () -> {
        System.out.println("complete");
        future.complete(null);
      }
    );
    future.get();
  }
}
```

```java
@RestController
public class SseController {

    private final List<SseEmitter> emitters = new CopyOnWriteArrayList<>();
    private final ExecutorService executor = Executors.newCachedThreadPool();
    private final AtomicLong counter = new AtomicLong();

    @GetMapping("/sse")
    public SseEmitter sse() {
        SseEmitter emitter = new SseEmitter(-1L); // -1 表示不设置超时
        emitters.add(emitter);

        emitter.onCompletion(() -> emitters.remove(emitter));
        emitter.onTimeout(() -> emitters.remove(emitter));
        emitter.onError((e) -> emitters.remove(emitter));

        // 可选：发送一个初始消息
        try {
            emitter.send(SseEmitter.event().name("INIT").data("连接已建立"));
        } catch (IOException e) {
            emitter.completeWithError(e);
        }
        return emitter;
    }

    // 模拟推送消息的示例方法
    public void pushMessage(String message) {
        for (SseEmitter emitter : emitters) {
            executor.execute(() -> {
                try {
                    emitter.send(SseEmitter.event().name("message").data(message));
                } catch (IOException e) {
                    emitter.completeWithError(e);
                }
            });
        }
    }

    // 模拟定时推送消息
    @GetMapping("/start-pushing")
    public String startPushing() {
        executor.execute(() -> {
            while (true) {
                try {
                    Thread.sleep(2000); // 每2秒推送一次
                    pushMessage("服务器推送的消息 " + counter.incrementAndGet());
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                    break;
                }
            }
        });
        return "开始推送消息";
    }

    // 停止推送消息
    @GetMapping("/stop-pushing")
    public String stopPushing() {
        executor.shutdownNow();
        return "停止推送消息";
    }
}
```

---
### SEIR模型是什么？
是预测传染病传播动态的数学模型，会把人群划分成不同的种类：
S：表示Susceptible，易感者，没有感染但有可能感染的人群
E：表示暴露者，已经感染，处于潜伏期的人群
I：表示感染者，已经感染
R：表示恢复着。

SEIR模型会通过一组微分方程来描述这四类人群随时间变化的趋势。我们这个推演模型就是根据这个模型，计算这四种人群在推演过程中的数量变化。

---
### Socket IO是什么？
可以在浏览器和后端服务器实现**实时、双向通信**的一个工具。
传输层可以基于HTTP长轮训，也可以基于Websocket。会监听客户端连接。可以广播，也可以创建不同房间，向单个房间发送消息。

---
### Kettle是什么？如何实现的？用了哪些设计模式？
1. 构建工作流Dag图，工厂模式创建不同类型的节点。用了邻接表来表示一个DAG图
2. 用策略模式支持不同类型的任务，每种任务可以继承 
3. 然后通过一个调度器，按照依赖顺序依次执行节点，每个节点输出作为下一个节点的输入， 
4. 通过todoTask，执行完了todo任务，在执行后续节点，用责任链模式把数据传给下一个节点。

在这个项目中，我实现了一个 DAG 引擎用于调度 ETL 任务。主要应用了以下几种设计模式：

---
### 项目难点：将其中一个xxl-job任务类型做成分片广播的分布式任务，由多个executor实例执行。
xxl-job本身就支持分片广播的路由策略，执行器的路由策略有随机、第一个、最后一个、最近最久、分片广播。
如果选择了分片广播的话，会发送参数3/5，表示当前分片索引为3，总分片数量为5。
执行器的jobHandler中接收到分片广播类型的任务后，会获取分片索引和分片总数这两个参数，然后用这两个参数生成子任务sql，
比如最后的where条件里加上范围查询，获取当前分片应该处理的数据范围。

