---
title: Flink面试题
author: Yu Mengchi
categories:
 - Interview
 - 面试知识点
 - Flink 
tags:
 - Interview
 - Flink
---

---
### Flink的使用场景？
实时流处理框架。处理实时数据。

---
### Flink的工作原理？工作流程？内部运行机制？
1. 首先用户提交jar包之后，Flink会生成StreamGraph，
2. 然后生成JobGraph，提交到JobManager上，
3. JobManager会生成ExecutionGraph
4. JobManager会根据执行图生成Task，把Task提交到TaskManager上。
5. 有TaskManager来执行Task。 整个流程就是这样的。

---
### Flink on Yarn提交作业的流程？
1. 提交jar包之后会提交到Yarn ResourceManager上
2. ResourceManager会分配一个Container给Flink ApplicationMaster，在ApplicationMaster中启动JobManager
3. JobManager会请求资源slots，Flink会向Yarn ResourceManger请求Container启动mTaskManager,
4. TaskManager启动之后，会提供slots，
5. JobManager把执行的Task分发给TaskManager,开始执行任务

---
### Flink的执行图有哪几种，分别是什么作用
1. StreamGraph：最开始的图，流程序图
2. JobGraph：StreamGraph在Client中经过算子chain链合并等优化后，转换成JobGraph，提交给JobManager
3. ExecutionGraph：JobManager会将JobGraph装换成ExecutionGraph
4. 最后是物理执行图



---
### WindowFunction、ProcessWindowFunction
都适用于对窗口内数据进行处理的函数。
1. WindowFunction:访问窗口的结果以及一些元数据(窗口的开始和结束时间)。
```java
    /**
 * Evaluates the window and outputs none or several elements.
 *
 * @param key The key for which this window is evaluated.窗口的键
 * @param window The window that is being evaluated.当前正在处理的窗口
 * @param input The elements in the window being evaluated.该窗口中的所有元素
 * @param out A collector for emitting elements.用来输出结果的收集器
 * @throws Exception The function may throw exceptions to fail the program and trigger recovery.
 */
    void apply(KEY key, W window, Iterable<IN> input, Collector<OUT> out) throws Exception;
```
2. ProcessWindowFunction：是一个更强大的接口，提供更多的控制和上下文信息，可以提供窗口执行的信息，包括状态和触发器相关的上下文。
```java
  /**
   * Evaluates the window and outputs none or several elements.
   *
   * @param key The key for which this window is evaluated.
   * @param context The context in which the window is being evaluated.提供窗口状态、当前处理时间、当前watermark值等上下文信息
   * @param elements The elements in the window being evaluated.包含窗口中的所有元素
   * @param out A collector for emitting elements. 用来输出结果的收集器
   * @throws Exception The function may throw exceptions to fail the program and trigger recovery.
   */
  public abstract void process(
          KEY key, Context context, Iterable<IN> elements, Collector<OUT> out) throws Exception;
```

---
### DataStreamSource、DataStream、KeyedStream、WindowedStream
1. DataStreamSource：表示数据流的源头，负责从外部系统(比如Kafka、文件、Socket)读取数据
```java
StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
// 从 Kafka 读取
Properties props = new Properties();
props.setProperty("bootstrap.servers", "localhost:9092");
DataStreamSource<String> kafkaStream = env.addSource(
    new FlinkKafkaConsumer<>("topic", new SimpleStringSchema(), props));
```
2. DataStream：通用数据流，表示一个无限的、连续的数据流，是所有流操作的基础，支持各种转换操作(map,filter,keyBy)
3. KeyedStream:按键分区的数据流，将数据流按键进行分区，确保相同键的数据由同一个实例处理
- 通过KeyBy(event -> event.getUserId()方法得到
- 后续操作只能应用键控操作(比如window，process),不能直接调用非键控操作(如union)
4. WindowedStream: 表示将无限流按时间或数量划分为有限的"桶"，便于批量处理
- 窗口创建后，需通过apply、reduce等方法定义窗口内数据的处理逻辑
- 窗口类型有很多种，比如支持滚动窗口、滑动时间窗口、会话窗口

```java
KeyedStream<MyEvent, String> keyedStream = ...;

// 滚动时间窗口（每 5 分钟一个窗口）
WindowedStream<MyEvent, String, TimeWindow> tumblingWindow = 
    keyedStream.window(TumblingEventTimeWindows.of(Time.minutes(5)));

// 滑动时间窗口（窗口大小 10 分钟，滑动步长 5 分钟）
WindowedStream<MyEvent, String, TimeWindow> slidingWindow = 
    keyedStream.window(SlidingProcessingTimeWindows.of(Time.minutes(10), Time.minutes(5)));

// 会话窗口（根据活动时间动态划分窗口）
WindowedStream<MyEvent, String, TimeWindow> sessionWindow = 
    keyedStream.window(EventTimeSessionWindows.withGap(Time.minutes(10)));
```

> DataStreamSource(源头)->DataStream(通用流)->KeyedStream(按键分区)->WindowedStream(窗口化)

---
### keyBy、process、filter、window、trigger、connect、map、reduce
1. map(MapFunction<T, R> mapper):对每个元素应用函数，转换为新元素

2. filter(FilterFunction<T> filter):过滤元素，保留满足条件的元素

3. keyBy(KeySelector<T, K> key):将数据流按键分区，相同键的元素进入同一分区

4. window(TumblingProcessingTimeWindows.of(Time.days(1), Time.hours(-8))):将键控流划分为窗口
   在KeyedStream类里window方法的定义如下，可以看到返回的是WindowedStream：
```java
    public <W extends Window> WindowedStream<T, KEY, W> window(
            WindowAssigner<? super T, W> assigner) {
        return new WindowedStream<>(this, assigner);
    }
```

5. trigger(ContinuousProcessingTimeTrigger.of(Time.seconds(30)))：自定义窗口触发时机
   在WindowedStream类里的trigger方法定义如下，
```java
    public WindowedStream<T, K, W> trigger(Trigger<? super T, ? super W> trigger) {
        builder.trigger(trigger);
        return this;
    }
```

6. reduce方法，位于WindowedStream类内：对窗口内元素进行增量聚合(如求和、最大值)
   使用代码如下：
```java
windowedStream.reduce((x: EmiBillingInfo, y: EmiBillingInfo) => x.reduce(y), new CacheFilterProcessWindowFunction[EmiBillingInfo, EmiBillingInfo, String, TimeWindow] {
   override protected def transfer(in: EmiBillingInfo): EmiBillingInfo = in

                override protected def extractKey(input: EmiBillingInfo): String = input.redisValue()
            })
```

源代码定义如下：
```java
public <R> SingleOutputStreamOperator<R> reduce(
        ReduceFunction<T> reduceFunction, WindowFunction<T, R, K, W> function) {

    TypeInformation<T> inType = input.getType();
    TypeInformation<R> resultType = getWindowFunctionReturnType(function, inType);
    return reduce(reduceFunction, function, resultType);
}
```

7. process(ProcessFunction<T, R> processFunction):对每个元素处理，输出0个或多个元素
8. connect(DataStream<R> dataStream):连接两个数据流，保留各自类型，可共享状态

> 基础转换(map, filter)

> 分区和窗口(keyBy,window)

> 聚合与处理(reduce，process)

> 双流操作(connect)

---
### 什么是Flink窗口，为什么流处理需要窗口？Flink支持哪些类型的窗口？
将无界数据流切分成数据块进行处理，在窗口上执行聚合操作。

1. 滚动窗口Tumbling Window：固定大小，不重叠

2. 滑动窗口Sliding Window：固定大小，可重叠

3. 会话窗口Session Window：活动间隙界定，大小不固定


> Flink中的窗口算子一般会配置Keyed类型数据集操作，并结合watermark和定时器，提供时间语义的统计。
- Windows Assigner：定义窗口的类型(数据流分配到多长时间间隔的哪种窗口，比如1min的滚动窗口)
- Trigger：定义窗口触发的条件(比如窗口内元素达到一定数量，或者窗口时间到达)
- Evictor：定义窗口内元素的剔除规则(比如窗口内元素超过一定数量，或者窗口时间到达)
- Lateness：定义窗口内元素的延迟处理规则(比如窗口内元素延迟到达，或者窗口时间到达)
- OutputTag：侧输出流输出标签
- Window Function：定义窗口内元素的处理逻辑(比如窗口内元素求和，或者窗口内元素计数)

---
### Flink有哪些时间语义？
有三种时间语义
1. 处理时间Processing Time：数据被处理时的系统时间
2. 事件时间Event Time：数据实际产生时的时间(数据自带时间戳)
3. Ingestion Time：数据进入Flink系统的时间

> 事件时间是最符合业务语义的，但也面临数据延迟和乱序问题，所以有watermark机制

---
### Flink窗口在内部是如何实现的？窗口计算的生命周期是怎样的？
窗口操作通常由以下核心组件协同工作：
1. 窗口分配器(WindowAssigner)：决定元素被分配到哪些窗口
2. 触发器(Trigger):决定何时计算窗口结果
3. 窗口函数(Window Function):定义窗口计算逻辑
4. 移除器(Evictor):可选组件，用于在窗口函数前后移除元素

一个典型窗口操作的生命周期如下：
1. 窗口创建：数据到达时，窗口分配器决定它属于哪个窗口，必要时创建新窗口；
2. 数据累积：数据被添加到对应窗口的状态中
3. 触发计算：当满足触发条件时(如Watermark越过窗口结束时间),触发器启动计算
4. 窗口函数执行：对窗口中累积的数据进行聚合计算
5. 结果输出：计算结果被发送到下游
6. 窗口清理：窗口资源被释放，状态被清除

---
### 滑动窗口和滚动窗口，什么场景下应该选择哪种窗口？
1. 滚动窗口
- 固定大小、无重叠
- 每个元素只会分配到一个窗口
- 适合于周期性聚合计算：如每小时统计、每天汇总
2. 滑动窗口
- 大小固定、可以重叠
- 每个元素可能分配到多个窗口
- 由两个参数定义：窗口大小和滑动间隔
- 适用于滚动平均类计算，比如"每分钟计算过去5分钟数据"

---
### watermark是什么？
watermark是处理延迟数据的机制，比如在一个窗口内，当位于窗口最小watermark的数据达到后，表示该窗口内的所有数据都已到达，会触发窗口计算

watermark本质上是一个时间戳标记，表示小于此时间戳的数据应该已经到达，可以安全触发所有截止时间小于等于T的窗口计算

---
### Watermark生成机制，有几种水印，Watermark是怎么生成的？
1. 周期性生成PeriodicWatermark：按照固定的时间间隔自动生成和发出，周期性的生成水印
2. 标点式生成PunctuatedWatermark：有数据流中的特定标记事件触发
3. 自定义生成

---
### watermark如何解决乱序问题
1. 延迟窗口触发：给予迟到数据一定的等待时间
2. 处理迟到数据：通过side output或更新结果处理超过水位线的数据

---
### checkpoint是什么？怎么做的？
checkpoint是创建状态快照的，可以实现故障恢复、保证exactly-once语义

会通过barrier机制，在数据流中插入barrier，当barrier到达时，会触发checkpoint。

1. jobmanager负责触发checkpoint，到达预定的时间间隔后，jobmanager向source发送barrier
2. barrier会随着算子执行跟随数据传播
3. 到达taskmanager后，会执行本地状态快照
4. taskmanager会向jobmanager报告状态快照的状态
5. 所有taskmanager都完成状态快照后，jobmanager会标记checkpoint成功完成。

什么是barrier对齐？
> 如果有多个数据流，会等待所有流的barrier到达后，才执行checkpoint，可以保证状态一致性。

---
### Flink的状态是什么？
某个时间点的数据快照

有Keyed State和Operator State两种类型
1. Keyed State：是基于键的状态，每个键都有自己的状态
 - Value State：一个键对应一个状态值
 - List State：一个键对应一个状态列表
 - Map State：一个键对应一个Map
2. Operator State：是基于操作符的状态，每个操作符都有自己的状态
 - List State:列表状态算子，将状态存储为列表数据
 - Union List State:与List State类似，但是当出现故障时可以恢复
 - Broadcast State：广播状态算子，将状态广播到所有并行实例，多个task共享状态

---
### Flink状态后端(State Backend)是什么？
保存状态，管理状态

1. MemoryStateBackend：适合测试环境，存储小状态
- 状态存储在JobManager的内存
- checkpoint存储在JobManager的内存
2. FsStateBackend
- 状态存储在TaskManager内存或堆外内存
- checkpoint存储在外部文件系统(HDFS)
3. RocksDBStateBackend:适合生产环境，存储大的状态
- 状态存储在TaskManager本地RocksDB
- checkpoint存储在外部文件系统(HDFS)

---
### ValueState、ValueStateDescriptor
两个都是用于状态管理的组件，可以保存和访问每个键的状态数据。
1. ValueState：是一个接口，表示一个可以存储单个值的状态。比如在计算每个用户的累计积分时，可以使用ValueState<Integer>来存储每个用户的当前积分
- value():获取当前状态的值。如果之前没有设置过值，则返回null；
- update(T value):更新状态的值
- clear():清除当前状态
2. ValueStateDescriptor：是用来创建ValueState实例的描述符类，定义了状态的名字、类型信息。如果要使用状态，首先需要定义一个ValueStateDescriptor，然后通过这个描述符来获取相应的ValueState实例。

---
### Flink的内存管理
1. JobManager的内存管理 jobmanager.memory.process.size
 - jvm堆内内存:jobmanager.memory.heap.size
 - jvm堆外内存:jobmanager.memory.off-heap.size
 - jvm元空间
2. TaskManager的内存管理 
 - jvm堆内内存：包括框架堆内内存和任务堆内内存
 - 堆外内存：


---
### Flink有哪些优化的措施
以下是一些Flink可以进行的优化措施：

1. 并行度调整：调整任务的并行度，以提高执行效率和吞吐量。
2. 内存管理：使用Flink的堆外内存管理机制来减少垃圾回收的开销，提高处理性能。
3. 数据倾斜解决方案：处理数据倾斜的方法包括打散、打分区、局部聚合、二次分区等，可以根据具体情况选择合适的方法来解决数据倾斜问题。
4. 合理使用缓存：在某些场景下，可以使用缓存来减少网络传输和IO开销，提高处理效率。
5. 文件系统选择：选择合适的文件系统来存储数据，以保证数据的可靠性和读写性能。
6. 状态管理：使用状态后端来管理Flink应用程序中的状态，以实现快速恢复和高可用性。
7. 合理配置检查点：检查点机制可以保证数据的一致性和可恢复性，合理配置检查点的间隔和超时时间，可以提高应用程序的性能和可靠性。
8. 使用数据结构：Flink支持多种数据结构，如Broadcast State、List State、Map State等，可以根据具体应用场景选择合适的数据结构，以提高处理效率和减少内存开销。
9. 流水线优化：对于复杂的任务流程，可以采用流水线优化技术，将多个操作合并为一个流水线，减少数据在内存中的复制和传输，提高处理效率。
   通过执行以上措施，可以显著提高Flink应用程序的性能和可靠性。

---
### Flink任务通常会出现哪些问题？
背压

数据倾斜

在Flink任务中，常见的问题包括：
1. 数据倾斜：当输入数据不平衡时，会导致某些任务的负载过重，导致处理速度变慢，甚至整个任务崩溃。
2. 内存溢出：当Flink任务处理大量数据时，可能会导致内存溢出，需要合理配置内存参数，使用堆外内存等机制来减少内存开销。
3. 网络延迟：当任务中涉及到网络传输时，可能会出现网络延迟问题，需要优化网络传输机制，减少网络传输开销。
4. 数据丢失：当任务中出现数据丢失时，需要检查任务的容错机制是否正确配置，以及数据源是否正确。
5. 任务调度问题：当任务调度不合理时，可能会导致任务不均衡，需要优化任务调度机制，以提高任务执行效率。
6. 状态管理问题：当任务中涉及到状态管理时，需要合理配置状态后端，以保证状态的可靠性和恢复性。
7. 并发控制问题：当任务中涉及到并发控制时，需要合理配置并发控制机制，以避免出现竞争条件和死锁等问题。
8. 应用程序设计问题：当应用程序设计不合理时，可能会导致性能下降和代码复杂度增加，需要合理设计应用程序架构，以提高应用程序的可维护性和可扩展性。
   针对以上问题，需要根据具体情况采取相应的优化措施，以保证Flink任务的稳定性和高效性。

---
### 背压问题
现象：
1. 大量任务等待
2. 报checkpoint超时
3. kafka数据堆积，无法消费
4. Flink UI界面的backpressure页面出现红色high标识

原因：
1. task任务逻辑复杂，处理速度慢
2. 网络波动
3. 有数据倾斜，内存不足；某个task变慢，由于barrier对齐，导致其他task整体变慢

解决：
1. 上游限流
2. 加大执行内存
3. 查看代码，是否有数据倾斜(预聚合key或拆分数据)
4. 查看哪些task出现问题

---
### Flink怎么实现exactly-once
1. 有checkpoint机制
2. 执行checkpoint时候有二阶段提交机制，等所有的checkpoint都完成后，才会提交数据到sink输出端

---
### 怎么处理迟到数据
1. 有watermark机制，可以配置最大延迟时间，一定程度上允许数据延迟
2. 可以把延迟数据输出到side output侧输出流

---
### Flink的双流join
1. join算子
2. coGroup算子，可以指定怎么处理窗口内的两个集合的数据，所以可以实现left join或right join
3. intervalJoin:是基于偏移时间得到两个流的数据，不像上面两个是通过窗口获取两个数据
4. connect

---
### 数据重复怎么办
1. 可以用groupByKey聚合去重
2. 可以借助Redis Key，使用Hset完成去重
