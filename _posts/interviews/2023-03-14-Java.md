---
title: Java基础
author: Yu Mengchi
categories:
  - Interview 
  - 面试知识点
  - Java基础
tags:
  - Interview
  - Java
---
# Java基础面试题

---
### java 8和11有什么区别
主要是一些新特性和一些改进的变化：
1. 引入一个HTTP客户端API，支持HTTP/2协议 
2. 引入了ZGC，垃圾回收的暂停时间会更短；
3. 引入了TLS 1.3 传输层安全协议TLS 1.3版本；
4. 在lambda表达式里可以使用var关键字表示参数类型，可以省略类型名，会变量的类型推断；
5. 移除了Java EE模块;
6. 可以直接用java命令运行一个单独的java文件，之前都需要先编译javac xxx.java生成class文件，再运行java xxx.class文件；可以简化原型开发，简化教学；
7. 引入了动态类文件常量，新增了两种常量池类型，CONSTANT_Dynamic和CONSTANT.InvokeDynamic，增强类文件中常量的表达能力

---
### invokedynamic是什么？
用于在运行时动态解析方法调用点，java的方法调用由以下字节码指令处理：
- invokestatic：调用静态方法
- invokevirtual：调用实例方法
- invokeinterface：调用接口方法
- invokespecial：调用构造器、私有方法或父类方法
这些指令的共同特点是方法调用点在编译时已确定，运行时无法改变。

invokedynamic可以在运行时动态创建方法调用逻辑，

> jvm遇到invokedynamic指令后，会调用对应的引导方法，引导方法会返回一个Callsite对象，包含目标方法，jvm会缓存Callsite，后续调用直接使用缓存的方法。

应用场景：Lambda表示式的方法调用，避免了传统匿名内部类的冗余开销。
```java
Runnable r = () -> System.out.println("Hello");//不用创建方法
```

---
### java和scala有什么区别
它们两个都是运行在JVM上的语言，都会编译成字节码文件，所以scala程序里可以直接调用java库。Spark就是用Scala写的。
- scala会更简洁，有强大的类型推断能力，定义变量的时候可以用var省略具体的类型；
- scala的函数式编程会更全面一点，支持很多高阶函数；
- scala处理并发问题会更容易编写，更高效，通过Akka库；

---
### scala和java对比？

scala也是一种基于java虚拟机的编程语言，。有以下优点：
- 更简洁
- 函数式编程：scala提供了强大的函数式编程能力，可以更方便地处理并发；
- 静态类型系统：scala的静态类型系统可以提高代码的可靠性和健壮性，能够在编译时捕获更多的错误。

为什么scala更灵活呢？
因为scala支持函数式编程和面向对象编程两种范式的混合使用。
1. 比如可以使用scala中的高阶函数对列表进行**函数式编程**，过滤filter、聚合reduce操作等。如：list.map(x=> x*x),list.filter(x => x % 2 == 0)
2. 可以使用scala中的**样例类**来定义数据类，使代码更简洁，比如：

```scala
case class Person(name: String, age: Int) 

val person = Person("Alice", 25)

//通过copy生成新的实例
val updatedPerson = person.copy(age = 26)
```
3. 可以使用scala中的**隐式转换**来扩展类的功能：

```scala
//为Int类型添加isEven方法
implicit class IntExtensions(val i: Int) {
  def isEven: Boolean = i % 2 == 0
}

val number = 4

//调用IntExtentions中的isEven方法
val isNumberEven = number.isEven
```

> 使用scala中的隐式类型转换可以方便地扩展类的功能，可以在编译期自动地将一个类型转换成另一个类型，而无需显式地调用转换函数，
> 比如要比较一个Int类型的变量和一个String类型的变量时，这两个类型不一致，没法比较。这时可以定义一个隐式转换函数，将Int类型隐式转换为String类型，使得它们可以被比较。

```scala
implicit class IntOps(val i: Int) {
  def addOne: Int = i + 1
  def isEqualTo(s: String): Boolean = i.toString == s  //为Int类型添加一个隐式类型转换函数，使得可以比较Int和String类型。
}

val number: Int = 42
val result = number.addOne
val isEqual = number.isEqualTo("42")
```

---
### var val 类型检测在哪里？
- var的值是可变的
- val值不可变，类似与java的final变量，天然线程安全；(引用可以变)

scala是类型无关的语言，支持面向对象编程和函数式编程。

scala的类型检查是在编译时进行的，使用静态和动态类型检查的组合。scala的类型系统基于一种称为"类型推断"的概念，允许程序员
省略显式类型注释，编译器将根据使用值的上下文自动推断类型。

- 静态类型检查：在编译时检查变量的数据类型，java、scala、C语言，需要声明变量的类型；
- 动态类型检查：在运行时确定变量的类型，python、ruby语言。

---
### play和springboot对比？play中有ioc、aop这种吗？
Play框架和Spring框架的区别：
1. 架构模式：Play框架采用了一种名为"reactive model"的架构模式，这种模式支持异步和非阻塞式的IO操作，可以更高效地处理大量请求。
   Spring框架则是基于传统的"layered architecture"架构模式，支持阻塞式IO操作。
2. 编程语言：Play框架是基于Scala编写的，而Spring框架是基于java编写的。
3. Web框架：Play框架提供了一个全栈式的web框架，包括路由、模板引擎、表单处理、JSON处理等功能。
   Spring框架则是一个由多个模块组成的框架，其中包括了Spring MVC和Spring Boot等与Web相关的模块。
4. 依赖注入：Spring框架是以依赖注入为基础的框架，内置了一个IOC容器。Play框架也支持依赖注入，但它是使用一个叫Guice的第三方库来实现的。

在Play框架中，虽然没有像Spring框架那样的IOC容器和AOP支持，但是它也可以通过Guice库进行依赖注入。Play框架也有类似于AOP的功能，
称为Action Composition，可以用来处理模块化的路由和请求处理。

---
### 在Play中，怎么进行依赖注入？

有两种方式：
1. 构造函数注入
2. Guice继承，通过Module类配置绑定关系

在Play中可以通过Guice库实现依赖注入：
1. 定义bean类
2. 创建Guice module
3. 使用bind()方法将bean绑定到Guice module上

```scala
// 首先定义一个bean
class MyBean{
  def doSomething(): String = "hello world"
}

// 然后创建一个Module，用bind()方法绑定bean到module上
class MyModule extends AbstractModule with ScalaModule {
  override def configure(): Unit = {
    bind[MyBean].asEagerSingleton() //bind()方法用于将接口或类绑定到其实现上
  }
}

// 在Controller或Service类中，通过@Inject注解注入bean
class MyController @Inject()(myBean: MyBean, cc: ControllerComponents) extends AbstractController(cc) {
  def index(): Action[AnyContent] = Action {
    Ok(myBean.doSomething())
  }
}
```

---
### Play框架中使用Hibernate访问数据库表的方法
1. 在build.sbt文件中添加依赖hibernate-core
2. 在application.conf中配置db.default.url, db.default.driver, db.default.user和db.default.password
3. 创建PersistenceConfig， 创建User实体类
4. 创建UserRepository类，执行CRUD方法。
5. 最后在Controller中可以使用UserRepository类执行CRUD操作

---
### 闭包
scala中的闭包是指一个函数可以访问其定义范围之外的变量或值的行为。
```scala
def add(a: Int): Int => Int = {
  (b: Int) => a + b
}

val addTwo = add(2)
println(addTwo(3))

```

---
### Integer a = 1, b = 1; a == b?
结果是true，因为会自动装箱，并且缓存值，缓存范围是-128到127，超出范围会创建新对象。

---
### 堆和栈的区别
1. 栈是由系统自动分配的，在方法调用的时候，存放函数的参数值、局部变量的值。会存放基本类型数据和对象的引用变量，数据可以直接拿来访问，速度比堆快。
2. 堆是手动申请，是很大的内存区域，不连续的内存区域，系统会用链表存储空间内存地址。存放创建的对象和数组，创建一个对象放入堆中的同时，也会在栈中创建一个指向该对象堆内存中的地址引用变量。

---
### new一个对象有什么过程？
顺序：类加载检查->是否已加载类->加载类->分配内存->初始化->设置对象头->执行init方法

会先查看对应的类有没有加载到内存中，如果没有的话，就会通过类的全限定名来加载这个类，加载并初始化之后，再创建这个对象。

加载类的过程会遵循双亲委派模型，类加载器收到类加载的请求后，会先委托给父类加载器加载，最终会传送到启动类加载器，只有当父类加载器无法完成加载请求的时候，
才会自己尝试加载。

jvm会通过类加载机制把类的数据从字节码文件加载到内存，并对数据进行校验、转换解析和初始化，最后
形成可以被虚拟机直接使用的java类型。

加载的过程会经过：加载->验证->准备->解析->初始化->使用->销毁 的一个过程
1. 加载阶段会由类加载器根据类的全限定名读取该类的二进制字节流，然后生成对应类型的java.lang.Class对象实例；
 - 字节码来源：包括从本地路径下编译生成的.class文件，从jar包中的.class文件，从远程网络，以及动态代理实时编译；
 - 类加载器：包括启动类加载器、扩展类加载器、应用类加载器、以及用户的自定义类加载器；
2. 验证阶段会验证加载进来的字节流是否符号虚拟机的规范要求
 - 文件格式的验证；
 - 对于元数据的验证，比如该类是否继承了被final修饰的类？类中的字段，方法是否与父类冲突？
 - 对于字节码的验证：保证程序语义的合理性，比如要保证类型转换的合理性；
3. 准备阶段会为静态变量分配内存，设置初始值(被final修饰的static变量，会直接赋值)
4. 解析阶段会将常量池中所有的类名、方法名、字段名这些符号引用转换为直接引用，也就是具体的内存地址或偏移量。(得到类或者字段、方法在内存中的指针或者偏移量，以便直接调用该方法)
 - 符号引用：即一个字符串，但是这个字符串给出了一些能够唯一性识别一个方法，一个变量，一个类的相关信息；
 - 直接引用：可以理解为一个内存地址，或者一个偏移量。比如类方法，类变量的直接引用是指向方法区的指针；而实例方法，实例变量的直接引用则是从实例的头指针开始算起到这个实例变量为止的偏移量。
5. 初始化会真正初始化静态变量和其他资源，开始执行类中代码
   
类加载完之后，创建真正的对象：

1. 在堆分配对象需要的内存(分配内存)
 - 分配的内存包括本类和父类的所有实例变量，不包括任务静态变量
2. 对所有实例变量赋初始值(初始化)
 - 将方法区内对实例变量的定义拷贝一份到堆，然后赋默认值
3. 执行实例初始化代码(执行初始化方法)
 - 初始化顺序是先初始化父类再初始化子类，初始化时先执行实例代码块然后是构造方法
4. 在栈区定义引用变量，然后将堆内的对象的地址赋值给它

---
### 字节码文件如何被jvm读取的？

---
### JVM加载class文件的原理机制

---
### 类加载的过程

---
### 编译的字节码文件中的主要内容是什么？

1. 魔数
2. 次版本号 主版本号
3. 常量池
4. 类名称 父类名称
5. 接口信息
6. 方法信息
7. 属性信息

---
### 对象在内存中的布局？
1. 对象头Header
 - MarkWord：对象自身的元数据，包括哈希码、分代年龄、锁标志位
 - Klass Pointer类型指针：指向类元数据的指针；通过这个指针确定这个对象是哪个类的实例；
 - 如果对象是数据，对象头还会存储数据长度
2. 实例数据Instance Data：存储对象中定义的实例变量的值。
3. 对齐填充Padding：保证对象在内存中的地址是8字节的整数倍；目的是提高CPU访问数据的效率。

---
### 说说对象分配规则

---
### java对象创建过程

---
### 类的生命周期

---
### 什么是继承和多态？有什么作用？

继承和多态都是面向对象编程中的概念。

继承是通过创建子类继承父类的机制，继承父类的属性和方法。作用是代码复用，和功能扩展。

多态是指同一个方法在不同上下文下有不同的功能，分为方法重写和方法重载。方法重写是子类重新定义父类的同名方法，方法重载是在同一个类中定义同名方法，但是参数列表不一样。作用是提高代码灵活性，

---
### java中抽象类和接口有什么区别？什么情况下被使用？

- 抽象类使用abstract声明，可以用抽象方法和非抽象方法，可以有任意类型的成员变量，单继承，通常表示为子类提供一些默认实现方法的时候会定义一个抽象类；
- 接口使用implements声明，方法默认都是抽象的，成员变量只能是常量，可以实现多个接口，表示的是定义一种行为规范，表示一种能力，一般会在策略模式、工厂模式时会使用接口。

---
### java中的异常处理机制是什么？常见的异常类型有哪些？如何捕获和处理异常？

java中的异常是通过类来表示的，所有的异常类都继承自Throwable类，Throwable有两个主要的子类，Error和Exception。

- Error表示程序运行时出现的严重错误，通常是由于系统资源不足，虚拟机故障这种不可恢复的错误引起的，比如OOM异常。
- Exception表示可以通过代码处理的异常，分为Runtime Exception和Checked Exception。运行时异常通常是程序逻辑错误引起的，比如NPE空指针异常，ArrayIndexOutOfBoundsException数组越界异常，java编译器不会强制要求程序员处理它们。
  Checked Exception通常是由外部环境引起的，java编译器会强制要求程序员处理它们。比如IOException,SQLException。

常见的异常类型有OOM，NPE，数组越界异常，IO异常

捕获和处理异常一般会用try catch finally throw这些手段，可以用try catch捕获异常，可以向上级抛出异常，也可以自定义异常。

---
### Java中的equals和hashcode方法的作用是什么？如何正确重写它们？

equals用于比较两个对象是否相等，在Object类的默认实现里会比较两个对象的引用是否相同；hashcode返回对象的哈希码值，在Object类中是基于对象的内存地址生成的。

如果两个对象equals方法判断是相等的，那么hashcode方法也应该相等，反之不一定，有可能会有哈希冲突。如果重写了equals方法，必须同时重写hashcode方法。

---
##### 1.重写hashcode方法？

可以使用Objects.hash方法简化实现，

---
#### 2. 什么时候重写equals方法？
1. 对象需要比较
2. 对象需要放到集合类里

> @Data注解会自动生成

---
##### 3.如何正确重写equals？

- 先通过==判断是否是同一个引用对象
- 再通过getClass检查类型是否匹配(不要使用instanceof，子类和父类会判定为相等)
- 最后再逐个比较字段是否相等。

---
### java中泛型是什么？有什么作用？如何使用泛型？

泛型是java中的一种编程机制，允许在定义类、接口、方法的时候使用类型参数，可以保证代码的复用和类型安全。

在定义类、接口或方法的时候在类名、方法名后面加上<T>，然后在使用的时候再指定具体的类型。

---
### java中的集合框架有哪些？特点和应用场景是什么？

List：有序、可重复

- ArrayList:基于动态数组实现，适合频繁访问随机元素
- LinkedList:基于双向链表实现，适合频繁插入删除元素
- Collections.synchronizedList：线程安全的动态数组

Set：去重 

- HashSet：基于哈希表实现，元素无序
- LinkedHashSet：基于哈希表和链表实现，保留插入顺序
- TreeSet：基于红黑树实现，可以自定义排序规则

Queue：先进先出

- LinkedList:
- PriorityQueue:基于堆实现，可以自定义比较器排序
- ArrayDeque：双端队列，支持在两端添加或删除元素

Map：键值对

- HashMap:基于哈希表实现
- LinkedHashMap:基于哈希表和链表实现，保留插入顺序
- TreeMap：基于红黑树实现，可以自定义键的排序规则
- ConcurrentHashMap：线程安全的哈希表

还有一些Stack栈，Collections.synchronizedList, Collections.unmodifiableList, ConcurrentHashMap, CopyOnWriteArrayList, BlockingQueue（阻塞队列，常用于生产者-消费者模型）

---
### 实现一个死锁的程序

```java
public class deadLock {

    private static final Object lock1 = new Object();
    private static final Object lock2 = new Object();

    public static void main(String[] args) {

        Thread thread1 = new Thread(() -> {
           synchronized (lock1) {
               System.out.println("线程1：拥有锁1");
               try {
                   Thread.sleep(100);
               } catch (InterruptedException e) {
                   e.printStackTrace();
               }

               System.out.println("线程1：等待锁2");
               synchronized (lock2) {
                   System.out.println("线程1：拥有锁1和锁2");
               }
           }
        });


        Thread thread2 = new Thread(() -> {
            synchronized (lock2) {
                System.out.println("线程2：拥有锁2");
                try {
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println("线程2：等待锁1");
                synchronized (lock1) {
                    System.out.println("线程2：拥有锁2和锁1");
                }
            }
        });

        thread1.start();
        thread2.start();
    }
}
```

死锁的四个必要条件：
1. 互斥条件：资源只能被一个线程占用
2. 占有并等待：线程占有资源同时等待其他资源
3. 不可剥夺：线程占用的资源不能被强制释放
4. 循环等待：存在线程在循环等待资源

为避免死锁，可以采取以下措施：
1.按顺序加锁
2.使用超时机制，比如tryLock方法
3.减少锁的粒度
4.使用高级并发工具，比如ReentrantLock提供的tryLock或Lock接口

---
### 线程池的好处，为什么不自己创建线程池？
1. 复用线程，管理线程
2. 线程复用，任务响应速度快
3. 可以通过任务队列和拒绝策略保证线程数量

> 尽量不要用Executors工厂类创建线程池，比如newFixedThreadPool会使用无解队列，会出现OOM

---
### 线程池参数怎么设置比较合理
1. 核心线程数(CPU密集型和IO密集型任务可以分开用不用的线程池)
 - cpu密集型： 线程数=cpu核心数+1
 - io密集型：线程数=cpu核心数*2

2. 最大线程数：
 - 如果任务队列选的是有界队列，那么maximumPoolSize应该大于corePoolSize，以应对突发任务；
 - 如果任务队列选的是无界队列，那么maximumPoolSize相当于无效的，队列可以无限创建任务，可能出现OOM

3. 任务队列
 - 有界队列(ArrayBlockingQueue):需要配合合理的maximumPoolSize，避免任务堆积过多
 - 无界队列(LinkedBlockingQueue):适合任务量稳定，不希望拒绝任务的场景，但是需要控制corePoolSize防止资源耗尽
 - 同步队列(SynchronousQueue):不存储任务，直接将任务提交给线程执行。比如Executors.newCachedThreadPool

4. 空闲线程存活时间
 - 一般60s

5. 拒绝策略
 - AbortPolicy：丢弃任务并抛出异常
 - CallerRunsPolicy：由调用线程执行该任务
 - DiscardPolicy：直接丢弃任务，不抛出异常
 - DiscardOldestPolicy：丢弃队列中最老的任务，然后重新提交当前任务

> 关键业务使用CallerRunsPolicy
> 非关键业务可以使用AbortPolicy或DiscardPolicy

---
### 线程的创建需要耗费哪些资源
1. 每个线程有独立的栈空间，通过-Xxs设置；
2. 需要操作系统的支持，执行系统调用pthread_create

---
### 线程之间通信有哪些方法？
1. 锁机制：互斥锁、条件变量、同步锁；volatile(共享内存)
2. 信号量机制：信号量是一种同步原语，用于控制对共享资源的访问。线程可以使用信号量来协调它们之间的操作
3. 信号机制

---
### 什么是同步原语？
同步原语是一种用于进程之间和线程之间同步的机制，访问共享资源，避免死锁。用于协调多个线程或进程之间的操作，以确保它们以正确的顺序执行。

同步原语包括互斥锁、条件变量、信号量等，它们提供了一种机制，使得在多线程或多进程的环境中，多个线程或进程可以协调它们之间的操作，以避免竞争条件和死锁等问题。

---
### 进程之间通信有哪些方法？
1. 管道pipe
2. 信号量semaphore
3. 共享内存shared memory
4. 消息队列message queue
5. 套接字socket

---
### 线程池有4个空闲线程和有100个空闲线程有什么区别？

---
### 线程上下文保留了哪些东西

指在JVM里的话
 - java虚拟机栈里保存的内容，比如局部变量表、操作数栈、方法调用栈
 - 程序技术器里保存的当前线程执行的字节码行号
 - 线程的局部存储
 - 线程持有的锁状态，也就是线程持有的monitor
 
---
### Java中的线程池是什么？如何使用线程池？运行的原理是怎样的？
线程池是一种线程的使用模式，维护了一个线程池，当有任务需要执行的时候，线程池会分配一个空闲线程来执行任务，如果所有线程都在忙，任务会进入等待队列，直到有线程空闲。

如何使用？
java中可以通过JUC包中的ExecutorService接口来使用线程池，实现类有ThreadPoolExecutor和Executors工具类。
1.Executors提供了多种静态方法来创建不同类型的线程池
- newFixedThreadPool(int nThreads):创建一个固定大小的线程池，线程池中的线程数量固定不变；
- newSingleThreadExecutor():创建一个单线程的线程池，所有任务按提交顺序依次执行；
- newCachedThreadPool():创建一个可以动态调节线程数量的线程池，线程池会根据需要创建新线程；
- newScheduledThreadPool(int corePoolSize):创建一个支持任务延迟执行或周期性执行的线程池。
2.第二种方式就是通过ThreadPoolExecutor构造函数创建线程池，可以更灵活的创建线程池。

```java

ThreadPoolExecutor executor = new ThreadPoolExecutor(
        corePoolSize,//核心线程数
        maximumPoolSize, //最大线程数
        keepAliveTime, //空闲线程存活时间
        unit,       //存活时间单位
        workQueue, //任务队列
        handler  //拒绝策略
  )

```

运行原理是：
1. 任务提交：当任务提交到线程池时，线程池会先检查当前线程数量是否小于核心线程数，如果是，则创建新线程执行任务
2. 任务排队：如果当前线程数已达到核心线程数，任务会被放到等待队列中等待执行
3. 线程创建：如果任务队列已满而且线程池中的线程数小于最大线程数，线程池会创建新线程来执行任务
4. 任务执行：线程从任务队列中获取任务并执行，执行完成后线程会继续获取下一个任务
5. 线程回收：如果线程在空闲时间后没有新的任务可执行，线程会被回收

> 使用线程池的优点是：使用线程池可以合理管理线程的创建和销毁，避免了频繁创建线程带来的性能开销，同时提高了系统的响应速度和资源利用率。

---
### 线程池使用无界队列的问题？
可能有OOM问题，如果使用的LinkedBlockingQueue无界队列，比如Executors.newFixedThreadPool()
```java
Executors.newSingleThreadExecutor();//LinkedBlockingQueue无限加入队列   任务过多会出现OOM
Executors.newScheduledThreadPool();//DelayedWorkQueue队列如果满了，阻塞
Executors.newFixedThreadPool(6);//LinkedBlockingQueue
Executors.newCachedThreadPool();//SynchronousQueue队列如果满了，抛异常  最大线程数是Integer.MAX_VALUE,会导致创建的线程数量过多，导致OOM
Executors.newSingleThreadScheduledExecutor();//DelayedWorkQueue
```

---
### 拒绝策略什么场景下使用

---
### 线程怎么结束？
1. 运行完了自动结束
2. 设置标志位，while循环判断标志位
3. 使用interrupt()中断线程

---
### java中的lock和synchronized的区别？
两个都可以用来实现线程同步，但是使用上有一些区别：
- 首先synchronized是java语言的关键字，用于同步方法或同步代码块；Lock是一个接口，ReentrantLock是它的实现类，需要显式地调用lock()方法获取锁，调用unlock()方法释放锁；
- 然后synchronized锁的释放是自动的，当同步方法或同步代码块执行完之后，锁会自动释放；Lock锁需要在finally块中调用unlock()方法来释放锁，否则可能会导致死锁。
- 还有就是Lock有很多其他的功能，比如可以通过tryLock()方法尝试获取锁，如果锁不可用会立即返回，还可以查询当前线程是否持有锁。
- 还有synchronized锁不支持公平锁，线程获取锁的顺序是随机的；Lock锁可以通过ReentrantLock的构造函数指定是否为公平锁。
- 还有Lock可以创建条件变量，然后通过条件变量的await(),signal()方法实现通知等待机制。
- 最后就是性能上，synchronized在JDK1.6版本之后进行了优化，添加了自旋锁、锁粗化、锁消除机制，性能上接近Lock。

> 使用总结的话，如果只需要简单的线程同步，而且对锁的功能要求不高的话，推荐使用synchronized，因为它更安全，更简单。
如果需要更灵活的锁操作，比如说想要tryLock、想要创建条件变量、或者创建公平锁的话，推荐使用Lock。

---
### Synchronized和Lock区别？
1. 锁的获取和释放方式不同，lock需要显式获取和释放
2. synchronized是可重入锁，一个线程可以多次获取同一个锁，
3. synchronized在获取锁失败的时候会一直等待，直到获取锁。而lock可以设置等待时间，也可以在等待过程中中断线程
4. synchronized是非公平锁，不保证等待时间最长的线程最先获取锁，而lock可以通过构造函数指定锁的公平性

---
### synchronized运行原理
首先synchronized是java中的一个关键字，一般用来修饰实例方法或同步代码块，实现线程同步。保证多线程访问同步代码的时候只有一个线程能获取到资源。

synchronized的底层实现是基于对象在内存中的存储格式来实现的，

一个java对象主要是由对象头、实例数据、对齐数据组成的，对象头里的mark word会有很多标记字段，标记字段里会存放对象运行时的一些状态信息，比如哈希码、GC分代年龄、锁的状态标志等。
1. 如果这个对象被当成锁来用的话，就会有指向Monitor的指针，Monitor是一个监视器类，里面有持有monitor的线程、有等待队列、还有计数器；
2. monitor就是对象监视器，线程会通过monitor enter和monitor exit指令来获取和释放锁对象。

---
### java 锁的实现原理

java提供了两种方式来加锁:synchronized、ReentrantLock

- synchronized修饰对象时：如果修饰的是对象，那么他是依赖于monitor对象来实现锁的机制的。当monitor被其他线程占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权。线程退出monitor的时候，执行monitorexit指令。

> synchronized的实现原理：synchronized的语义底层是通过一个monitor对象来完成，其实wait/notify等方法也依赖于monitor对象。

- synchronized修饰方法时：那么则是通过ACC_SYNCHRONIZED标识符来进行加锁的。


---
### Synchronized锁升级
虚拟机会根据锁的竞争情况升级锁的状态，减少性能消耗。

锁的状态分别是：无锁->偏向锁->轻量级锁->重量级锁。升级过程是单向的，只能从低到高。

- 无锁：没有对资源锁定，所有线程都能同时访问修改对象，但同时只能有一个修改成功。

- 偏向锁：只有一个线程进入同步代码，

- 轻量级锁：其他线程会通过自旋的方式获取锁，不会发生阻塞

- 重量级锁：原始的synchronized实现，其他线程会阻塞，只有当前线程释放锁，才会唤醒。


1. 当线程第一次获取锁的时候，进入偏向锁状态。会在对象头中记录该线程的ID，将锁标记位记为01；
2. 当其他线程尝试获取锁的时候，偏向锁会升级为轻量级锁。
 - 线程进入同步块前，jvm在当前线程的栈帧中创建一个名为Lock Record的空间，用于存储对象头的mark word拷贝
 - 通过CAS操作，尝试将对象头的mark word更新为指向Lock Record的指针；
    - 如果成功，线程获取到轻量级锁，锁标志位为00
    - 如果失败，说明有其他线程持有锁，当前线程进入自旋等待状态，也就是通过循环尝试获取锁
3. 当自旋次数超过阈值，轻量级锁升级为重量级锁，重量级锁会依赖操作系统的互斥量(Mutex),会导致线程挂起和唤醒，性能开销大
 - 重量级锁依赖操作系统的Mutex Lock实现，线程获取锁失败时会被挂起进入内核态，锁释放时再唤醒线程。
 - 锁标志位为10，mark word指向操作系统的互斥量

---
### synchronized保证可见性的原理？
内存模型和happens-before规则

---
### synchronized锁静态方法和锁普通方法有什么区别？
1. 实例对象：方法锁(默认为this)、同步代码块锁(自己指定锁对象)
2. 类：静态方法、或指定为Class对象

---
### HashMap和ConcurrentHashMap的实现原理？区别？
1.HashMap底层是基于数组和链表或者红黑树实现的，数组的每个位置称为桶，用于存储键值对，当多个键的哈希值相同时，也就是发生哈希冲突时，
这些冲突的键值对会存储在同一个桶中，形成一个链表，如果链表长度超过一个阈值，默认是8，链表会被转换成红黑树，提高查找效率。 
 - 插入键值对时，先计算键的hash值，然后用hash值与capacity-1做与运算，这个capacity是指数组的容量，得到这个键对应的数组的下标index值。
 - 当发生hash冲突时，也就是说多个键映射到同一个桶中，HashMap会使用链表法解决冲突，在同一个桶中形成链表。如果链表长度超过8，将链表转换成红黑树；如果链表长度减少到6或者更少，将红黑树转换回链表。
 - 扩容机制：当哈希表中的元素数量超过当前容量乘以负载因子时，这个负载因子默认是0.75，HashMap会触发扩容操作。扩容时，会创建一个新的数组，容量是原数组的两倍，然后将所有键值对重新映射到新数组中。
2.ConcurrentHashMap是线程安全的哈希表，底层结构和HashMap类似，但是为了支持线程安全，采用了分段锁或CAS操作。
 - 分段锁是在JDK早期版本中采用的方法，将数组分成多个段，每个段是一个独立的锁，使用分段锁减少锁的粒度，每个分段锁保护数组的一部分。
 - 在JDK1.8版本以后，ConcurrentHashMap使用CAS操作来更新数组中的节点，减小了锁的开销。

区别：
* HashMap不是线程安全的，多个线程同时写入的话可能导致数据不一致或抛出异常；而ConcurrentHashMap是线程安全的；
* HashMap在单线程环境中性能比较高，因为没有锁的开销；ConcurrentHashMap在多线程环境中性能更高，因为它通过CAS操作减少了锁的粒度；
* 底层实现上，两个都是使用数组+链表或红黑树，但是ConcurrentHashMap增加了分段锁或CAS操作；
* 扩容的时候ConcurrentHashMap扩容时支持并发操作，可以同时对多个段进行扩容；
* HashMap的迭代过程中如果有修改会抛出ConcurrentModificationException异常；

> 总结的话就是，如果需要在多线程环境中使用线程安全的哈希表，使用ConcurrentHashMap； 如果在单线程环境中，对性能要求较高，使用HashMap

---
### hashMap结构
hashMap底层是通过Entry类型的数据+链表实现的，Entry类型有四个字段，包括key、value、hash、和next指针，每个Entry数组项都会连接一个链表，会使用拉链法解决哈希冲突。同一个链表中存放哈希值和散列桶取模运算结果相同的Entry。

当链表长度大于8之后，链表会转化为红黑树。

---
### ConcurrentHashMap结构？get时会加锁吗？
在jdk1.8之前，通过segment分段锁实现并发访问，segment控制多个HashEntry，默认有16个segment分段锁，segment是继承自ReentrantLock实现的，

在jdk1.8之后，使用CAS操作支持更高的并发度，在红黑树的创建过程会用synchronized锁定桶头节点。

get不需要加锁，其他线程的修改会立即可见，因为Entry里的value和next都有volatile修饰，确保可见性。

---
### hashMap为什么不安全？
因为put操作，resize操作都没有加锁，不是原子操作，多线程环境下，可能丢失数据

---
### HashMap有什么问题?头插法，尾插法？
线程不安全

jdk8以后是尾插法，新节点插入链表尾部。避免产生环形链表

---
### HashTable为什么线程安全？
HashTable的方法调用，比如get，put都声明了同步方法，用synchronized修饰。

---
### HashMap和HashSet区别？
HashMap保存键值对，HashSet保存不重复的元素。

---
### 红黑树比链表的优点是什么？
- 查找效率高，时间复杂度O(logn)
- 支持排序

---
### 为什么不一开始就用红黑树？
红黑树每个节点需要保存颜色还有左右子节点指针，插入或删除需要旋转维持平衡。
链表每个节点只需要一个指针，数据量少的时候，链表的初始化和插入效率更高。

---
### 红黑树，平衡二叉树

---
### HashMap扩容条件是什么？为什么容量是2的幂次？
1. 当前元素数量超过阈值，threadhold=capacity * loadFactor 
 - capacity是数组长度，默认是16，必须是2的幂次
 - loadfactor是加载因子，0.75
2. 链表长度达到8，且数组长度小于64，则优先扩容，而非树化。

为什么是2的幂次：计算桶的索引的时候，可以用位运算加速计算，因为计算索引是index=(n-1)&hash，当n时2的幂次的时候，n-1的二进制全为1，这个时候&运算相当于取模运算，计算效率会更高。

---
### 为什么链表长度超过8的时候，转化为红黑树？
因为按照泊松分布，当加载因子为0.75时，长度为8的时候，红黑树查询效率优势明显；

---
### 有没有用过其他框架的HashMap？比如guava模块里的？

1. Guava里用Map创建  Maps.newHashMap();
2. 不可变map：new ImmutableMap.Builder().put().put().build();
3. 有序map：new ImmutableSortedMap.Builder().build()
4. 可以方向把value值映射到key键上，要保证value值唯一：HashBiMap.create()
5. 一个键关联多个值：MultiMap

---
### HashMap的loadFactor值为什么是0.75?

loadFactor值表示哈希表中存储元素的数量与哈希表大小的比率。当哈希表中存储的元素数量超过了负载因子乘以哈希表大小的阈值时，哈希表就需要进行扩容了。

需要考虑到时间和空间的成本，值太高会增加查询成本，值太低会空间利用率会变低。是一个经验值

---
### ConcurrentHashMap扩容时如何解决并发安全问题？在JDK1.8中如何保证线程安全？
用synchronized对桶的头节点加锁，迁移过程中通过CAS操作更新节点指针；

---
### JVM运行时数据区都有哪些？各自存储的哪些数据？程序计数器的作用？

JVM的内存结构有程序计数器、java虚拟机栈、本地方法栈、堆、方法区。
1. 程序计数器：可以看做是当前线程所执行的字节码的行号指示器，指向下一条要执行的指令；**存放的是当前线程正在执行的字节码指令的地址。**
2. java虚拟机栈：存储**局部变量表、操作栈、动态链接、方法出口信息**。每个线程会有一个自己的栈，每个线程中方法的调用又会在栈中创建一个栈帧。在栈中会存放编译器可知的各种基本数据类型、对象引用，当进入一个方法时，这个方法需要在栈中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。
3. 本地方法栈：和java虚拟机栈一样，也是为方法调用服务的。区别是本地方法栈是为虚拟机使用到的native方法服务的。**存放本地方法的局部变量表、操作数栈、方法出口信息。**
4. 堆：作用是**存放所有对象实例和数组**，从结构上可以分为新生代和老年代，新生代又可以分成Eden空间、From Survivor空间（S0）、To Survivor空间（S1），新生成的对象都是放在新生代的。
5. 方法区：**存储已被虚拟机加载的类信息（类的名称、字段信息、方法信息）、常量池、静态变量、即时编译器编译后的代码等数据。**

---
### 堆内存分配的步骤

1. 新创建的对象会分配到Eden区，Eden区内存不够的时候会触发MinorGC，对新生代区进行一次垃圾回收；
2. MinorGC会清除Eden区的没有被GC roots标记的对象，存活的对象会被复制到Survivor From区，然后标记这些对象的分代年龄为1；
3. Eden内存不够又会触发一次MinorGC，一样清理垃圾，From区也会被清理，没有被清理的对象会被复制到To区，清理Eden区和From区，然后From和To区互换，原来的To区成为下一次GC时的From区；
4. 一直这样重复，如果对象的分代年龄达到了15次，这个对象就会被复制到老年代；
5. 老年代内存不够时会触发Full GC清理整个堆空间，包括新生代和老年代。这个时候会会停止所有用户线程；
6. 如果Full GC后还没有更多的空间存放新对象就会发生OOM。

> 如果新创建的对象占用内存很大，会直接分配到老年代；

> 新生代：老年代= 1： 2  
> Eden区：Survivor区 = 8：2；
> From区 ： To区 = 1：1；

---
### 什么时候会触发full GC
1. 手动调用System.gc()方法，但也不保证立即触发；
2. 老年代剩余空间不足，无法通过空间分配担保时，
3. 元空间不足，元空间存放类元数据、字符串常量，如果加载的类太多了，比如通过动态代理加载了太多的类，导致元空间不足，超过MaxMetaspaceSize；
4. 堆内存空间不足，

---
### JVM的永久代会发生内存回收吗

---
### 哪些内存区域会触发OOM

---
### 元空间受jvm内存影响吗？
- 堆外内存：元空间不在jvm堆内存里，在本地内存中，不会影响到堆内存的使用。
- 但是还是可以通过设置jvm参数设置元空间大小的，-XX:MaxMetaSpaceSize。
- 元空间是在java 8中引入的，用于替换永久代，主要用来存储类的元数据，比如类名、接口名列表、常量池等。
- 如果没有类加载器引用某个类的时候，这个类的元数据也是可以被垃圾回收的。

> 方法区是规范。永久代和元空间都是实现。
> 在jdk1.8之前，方法区的实现是用永久代；在jdk1.8之后，方法区的实现是用元空间，并且不再使用虚拟机内存而是本地内存。

---
### 怎么判断对象可以被回收？
通过引用计数法或可达性分析算法来判断这个对象是否能被回收：
1. 引用计数法：会对每个对象记录其被引用的次数，当引用次数为0的时候，可以认为可以被回收
2. 可达性分析：会从根对象开始扫描，在依次扫面完能够到达的所有对象后，所有未被扫描到的对象就被视为垃圾对象进行回收。

---
### 可达性分析算法
将GC Roots对象作为起点，从这些起点开始向下搜索引用的对象，找到的对象都标记为非垃圾对象，其余未标记的对象都是垃圾对象。

GC Roots根节点有：线程栈的本地变量、静态变量、本地方法栈的变量等。

---
### JVM的分代年龄为什么是15
对象头里的Mark Word字段有GC分代年龄字段，GC分代年龄是4bit，最大是1111，就是15.

---
### 内存泄露和内存溢出的区别？
1. 内存泄露是指程序在申请内存后，无法释放已申请的内存空间就会造成内存泄露；对象使用后及时close、clear。
2. 内存溢出是指程序申请内存时，没有足够的内存使用。修改JVM参数增加堆内存、对代码分析，找出内存溢出的位置。

---
### 内存泄露有哪些？怎么检查
1. 文件流、网络连接、数据库连接没有关闭，导致对象无法被回收
2. 缓存没有设置过期时间，导致对象一直存在
3. ThreadLocal如果没有remove移除，会导致对象无法被回收

怎么检查：
1. jvm内置工具，jstat -gc pid interval 监控gc频率，如果老年代持续增长且full gc频繁，可能存在内存泄露； jmap -heap pid 查看堆内存使用情况
2. 生成堆转储文件，jmap -dump:format=b,file=heapdump.hprof pid 
3. 分析堆转储文件，MAT或Visual VM，统计各类对象的数量和占用内存，查找占用内存最大的对象
4. 检查代码，资源使用try-with-resources自动关闭；ThreadLocal在finally里remove


---
### JVM内存泄露定位

---
### 堆内存回收的步骤
可达性分析判断存活对象， GC Roots：
 - 虚拟机栈引用的对象；
 - 方法区中类静态属性引用的对象；
 - 方法区中常量引用的对象；
 - 本地方法栈引用的对象。
1. 垃圾标记：初始标记(暂停所有用户线程；仅标记GC roots直接引用的对象)，并发标记(与用户线程同时运行，从GC Roots开始标记所有可达对象)，重新标记(修正并发标记因用户线程活动导致的标记变动)
2. 垃圾回收算法：复制-整理算法

---
### GC原理

---
### gc调优目标
1. 减少GC的停顿时间
- 选择低延迟的GC收集器，比如G1、ZGC；
- 调整堆大小，减少GC次数，尤其是Full GC(老年代大一点)；
- 减少不必要的对象创建；

---
### jvm有哪些垃圾回收算法？CMS和G1使用什么场景

常见的垃圾回收算法有：
1. 标记-清除：标记所有存活对象，然后清除未标记的内存空间。缺点是会产生内存碎片；
2. 标记-复制：将存活对象复制到另一个内存区域，然后清理原区域。适用于新生代；
3. 标记-整理：标记存活对象，然后将它们移动到内存的一端，清理另一端的内存。适用于老年代；

常见的垃圾回收器有：
1. Serial收集器：特点是单线程，使用标记-复制算法；
2. ParNew收集器：是多线程版本的Serial收集器，适用于新生代；
3. Parallel Scavenge收集器：也是多线程，使用高吞吐量的应用；
4. Serial Old收集器：单线程，适用于老年代，使用标记-整理算法；
5. Parallel Old收集器：多线程，老年代，也是使用标记-整理算法；
6. CMS收集器：并发，目标是最小化停顿时间，使用标记-清除算法，适合对响应时间要求比较高的应用，比如web服务器。
7. G1收集器：特点是分区收集，把堆划分成多个区域，优先回收垃圾最多的区域。

使用场景：
1. CMS适用于对响应时间要求比较高的应用，适合老年代的垃圾回收；
2. G1适用于大内存、多处理器的机器，堆大小比较大而且需要低GC延迟的应用，优点是可以并行收集、分区收集、避免内存碎片。

总结的话CMS收集器适合对响应时间要求高的应用，但是可能会遇到内存碎片和停顿时间过长的问题。G1收集器更适合大内存、多处理器的服务器应用，尤其是需要低GC延迟和高吞吐量的场景。

G1的优点：
1. 分区收集，优先回收垃圾最多的区域，而不是整个堆，这样的话可以更灵活控制回收时间；
2. 可预测的停顿时间，G1提供一个参数叫-XX：MaxGCPauseMillis，每次垃圾回收时尽量控制停顿时间不超过这个值，G1会根据目标停顿时间和当内存使用的情况，动态调整每次回收的区域数量，从而实现更稳定的停顿时间；
3. 可以避免内存碎片：G1会在垃圾回收时将存活对象复制到其他区域，较少Full GC的频率。

G1回收过程：
1. 初始标记：暂停所有用户线程，标记直接可达的根对象，比如全局变量、栈帧中的引用。这个过程会很快；
2. 并发标记：用户线程继续运行，垃圾回收线程开始并发执行，从初始标记阶段标记的根对象开始，遍历整个堆，进行**可达性分析**，标记所有可达的对象。这个时候因为用户线程还在并发运行，所有可能会有新的对象被创建或者对象引用关系发生了变化，G1会通过Remembered Set（记忆集）来记录这些变化；
3. 最终标记：会根据并发标记阶段记录的对象修改，最终标记哪些对象是存活，哪些对象是垃圾

Young Collection-> Young Collection + Concurrent Mark -> Mixed Collection -> Full GC

---
### 哪些垃圾收集算法
1. 标记-清除：从根出发，标记所有可以到达的对象，不可到达的对象会回收
2. 标记-整理：和标记-清除类似，但是会将存活的对象移到一端
3. 复制：把堆分成同样的大小的两块，每次只使用其中一块，当这一块用完了，就将活跃对象复制到另一块，同时清空原来的块。通常使用在新生代
4. 分代收集：将堆分成几个代空间，有新生代，老年代，不同代的垃圾回收使用不同的算法，比如新生代会使用复制算法，老年代会使用标记-清除或标记-整理算法。

---
### JVM调优常用的工具以及命令？

1. jps: **jps -l -m**，显示进程主类全名和启动参数；
2. jstat:**jstat -gc pid 2000** 每2s输出对应进程的gc情况；
3. jmap: **jmap -dump:live,format=b,file=dmp.hprof 28920** 生成dump文件，还可以执行启动参数-XX:+HeapDumpOnOutOfMemoryError让出现OOM时自动生成dump文件；
4. jinfo: **jinfo -flag 11494** 查看和调整虚拟机运行参数；
5. jstack: **jstack -l 11494|more** 生成当前时刻的线程快照，每条线程正在执行的方法堆栈的集合，目的是定位线程出现长时间停顿的原因，比如线程间死锁、死循环、请求外部资源导致的长时间等待。
6. jhat: 分析dump文件，生成页面，也可以用MAT来分析，MAP分析dump文件需要使用的内存要小很多。

---
### 写一段10个线程之间轮流打印数字0-9的程序？

---
### 单例的好处，为什么要用单例
1. 只有一个实例，比如需要日志对象、数据库连接池、应用的配置中心，计数器，工具类的日志记录对象Logger，缓存对象CacheManager
2. 提供全局的访问，适合需要几种管理资源或状态的场景

---
### 单例和静态类实现有什么区别
1. 单例可以实例化，静态类只能通过类名直接访问
2. 静态类用在一些工具类上，比如Math，Collections类，不需要维护状态时，只需要提供工具方法时可以用静态类，而且静态类在类加载的时候初始化，是线程安全的。

---
### 写一段单例模式代码？为什么要使用这种加锁模式？双重检查锁为何要加volatile？

单例模式有懒汉式、饿汉式、双重加锁校验式

```java
/**
 * 懒汉式
 */
public class Singleton { 
    //保证只有一个入口getSingleton方法获取对象，不然直接获取可能为空
  private static Singleton singleton;

  //保证不让通过构造函数创建对象
  private Singleton() {
  }

  //保证可以通过静态方法访问入口方法
  public static Singleton getSingleton() {
    if (singleton == null) {
        singleton = new Singleton();
    } 
    return singleton;
  }
}
```

```java
/**
 * 双重加锁校验 DoubleCheckedLocking DCL
 */
public class Singleton{
  
    //确保可见性和禁止指令重排序
    private static volatile Singleton instance;
  
    private Singleton() {}
  
    public static Singleton getInstance() {
        if (instance == null) {//第一次判空，防止不必要的加锁操作，提高性能
            synchronized(Singleton.Class) { //确保线程安全，获取锁防止其他线程已经创建对象
                if (instance == null) { //第二次判空，防止当前线程在临界区时，其他线程已经创建了对象
                    instance = new Singleton();
                }
            }
        }
        return instance;
    }
  
}

```

---
### 使用多线程应该注意的事项？
1. 访问共享变量的时候需要注意线程安全。
2. 使用锁机制的时候防止死锁。
 - 按固定顺序获取锁
 - 限制加锁时间，通过tryLock()尝试获取锁
3. 使用线程池处理任务，设置合理的参数。

---
### 实现线程安全的方法有哪些？
1. 互斥同步(阻塞同步)：
- synchronized关键字
- JUC包的ReentrantLock
2. 非阻塞同步
- volatile关键字
- 原子类(AtomicInteger)
3. 无同步方案
- 可重入代码
- 线程本地存储ThreadLocal：将数据限制在单个线程内

---
### 多线程加锁需要注意的点(细粒度，避免死锁)
1. 避免死锁
 - 按固定顺序加锁
 - 超时机制，通过tryLock()尝试获取锁
2. 仅锁定必要的资源，最小化锁的粒度，缩小锁的范围，避免串行化依赖；
3. 优先使用原子类，并发集合。
4. 异常处理，在finally里释放锁。

---
### JVM的内存模型？

- 程序计数器：作为当前线程所执行的字节码的行号指示器。选择下一条需要执行的字节码指令。
- java虚拟机栈：描述java方法执行的内存模型，每个方法执行的同时都会创建一个栈帧，存储局部变量表、操作数栈、动态链接、方法出口等信息。
- 本地方法栈：和虚拟机栈作用类似，虚拟机栈是为执行java方法服务，本地方法栈是为虚拟机使用到的本地方法服务。
- 堆：基本上所有的对象实例和数组都在堆上分配，是垃圾收集的主要区域。
- 方法区：和堆一样也是线程共享的区域，用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。
- 运行时常量池：方法区的一部分。
- 直接内存：不是虚拟机运行时数据区的一部分。jdk8以后方法区的实现元数据区就是位于直接内存中，而不是java堆中。

---
### jvm优化；

---
### 如何排查oom？如何定位线上OOM问题？垃圾收集器的参数配置

一些常用的JVM配置参数

- -Xmx(堆内存最大值) 4g  -Xms(堆内存初始值大小) 4g 设置堆内存
- -XX：UseG1GC -XX：MaxGCPauseMIllis=50  指定GC算法
- -XX：ParallelGCThreads=4 指定GC并行线程数
- -XX：+PrintGCDetails -XX：PrintGCDateStamps   打印GC日志
- -Xloggc:gc.log  指定GC日志文件
- -XX：MaxMetaspaceSize=2g   指定Meta区的最大值
- -Xss 1m  设置单个线程栈的大小
- -XX：+HeapDumpOnOutOfMemoryError  -XX：HeapDumpPath=/usr/local/  指定堆内存溢出时自动进行Dump

---
### jvm工具

- jps：与linux上的ps类似，可以查看虚拟机的进程，可以查看本地运行着几个java程序，并显示他们的进程号。
- jstat：监视jvm内存内的各种堆和非堆的大小及其内存使用量
- jstack：堆栈跟踪工具，一般用于查看某个进程包含线程的情况
- jmap：打印出某个java进程内存内的所有对象的情况。一般用于查看内存占用情况。生产堆转储文件
- jinfo：可以输出并修改运行时的java进程的一些参数
- jconsole：一个java GUI监视工具，可以以图表化的形式显示各种数据，并可通过远程连接监视远程的服务器的jvm进程。
- top：查看当前所有进程的使用情况，cpu占用率、内存使用情况、服务器负载状态等参数
- ps：

---
### ThreadLocal实现原理？

---
### ThreadLocal类是否线程安全？什么情况出现线程安全问题？如何解决？

ThreadLocal可以实现线程本地存储，把共享数据的可见范围限制在一个线程里面，这样的话不需要同步操作也能保证数据互不影响。
原理就是每个线程里面都有一个ThreadLocalMap对象，map里存放了所使用的ThreadLocal对应的value值，每次线程调用get或set方法的时候都会先获取
线程对应的ThreadLocalMap，然后对map里的键值对修改。

可能出现内存泄漏的问题，解决方法就是每次使用完ThreadLocal后执行remove操作。

---
### AQS是如何实现的？

AQS是juc里的一个抽象基类，可以在多线程环境下实现线程安全和并发控制。
AQS内部是一个存放等待线程的双向链表，有一些原子操作实现对状态的管理。AQS定义了一些方法比如acquire、release等，不同的同步器子类可以实现这些方法实现
不同的同步策略。


---
### CAS操作

CAS操作是一种原子指令，用于解决并发环境下共享数据的原子更新问题。juc里的原子类会使用到CAS操作。
操作包含三个操作数：内存位置（或者说变量）、预期值和新值。
执行过程的话：

1. 首先会读取当前内存位置的值，保存下来作为预期值
2. 然后在写入的时候，会比较预期值和当前内存位置上的值是不是相等，如果相等，说明没有其他线程修改过，将新值写入到内存位置，更新完成；
3. 如果不相等，说明有其他线程修改过，本次cas操作失败，需要重试。

---
### CAS操作三大问题，以及怎么解决
1. ABA问题：使用CAS操作的时候，比如原子类的操作时，可能会出现ABA问题，就是在判断内存地址的值等于期望值的时候，有可能被其他线程修改过，但是CAS操作没法感知这种修改，可能导致逻辑出错。
 - 解决方法：使用AtomicStampedReference带引用的原子类，会保存reference对象引用和stamp，这个stamp可以看做是版本号，每次更新引用的时候也会更新版本号，这样即使引用的值变回原来的值，但是版本号会不一样，所以可以解决ABA问题；
2. 长时间自旋问题：原子类设置值的底层实现有一个do while循环，如果while条件不满足的话，会无限循环。
 - 解决方法：使用LongAdder类，它会有一个base和cell[]数组，线程会分散到不同的cell进行累加，减少冲突；
3. 一般的Atomic原子类只能保证一个共享变量的原子操作，如果需要对多个共享变量保证原子性，CAS做不到
 - 解决方法：使用AtomicReference类，把多个变量放到一个对象里，进行CAS操作

---
### 两个线程同时对一个被volatile修饰的变量进行自增操作，结果如何，应如何保证结果正确？
volatile只能保证变量的可见性，没法保证原子性，所以结果可能小于预期值。

如果要保证原子性，只能用synchronized(加锁)，原子类(CAS无锁方案)，LongAddr等(分段累加)。

---
### volatile的实现原理

volatile是java中用来修饰变量的一个关键字，可以保证线程之间变量的可见性和有序性

1. 可见性就是说当一个线程修改了volatile变量的值的时候，这个变量的新值会立即写回到主内存，这样的话就可以确保不同线程对变量的读取操作都能获取到最新的值。
   实现可见性的原理就是java内存模型中规定当一个线程要读取volatile变量的时候，会直接从主内存中获取最新的值，而不是从线程的本地内存中获取，
   同样要修改volatile变量的时候，会立即将新值写回到主内存，这样的话就能保证其他线程看到最新的值。
2. 有序性就是说，在进行读取和修改volatile变量的时候，会按照在代码中的顺序执行，不会和其他指令发生重排序，保证了操作的有序性。
   实现的原理就是volatile变量会使用内存屏障的机制来禁止指令重排序。在volatile变量的读写操作前后会插入相应的内存屏障，确保所有的读写操作都按照代码的顺序执行。

但是volatile关键字没法保证原子性，也就是说当多个线程同时对volatile变量进行操作时，还是有可能出现竞争的情况。
如果需要保证原子性的话，可以考虑使用锁或者原子类来替代volatile。

---
### gc算法有哪些？

- 标记-清除算法：首先遍历内存空间，标记还在被引用的对象，然后清除所有未标记的对象。该算法的缺点是会产生内存碎片，影响内存利用效率。
- 复制算法：将内存空间分成相等的两部分，每次只使用其中一部分，当一部分内存使用完之后，将存活的对象复制到另一半内存中，然后清除该部分内存中的所有对象。
  该算法的缺点是每次只能使用一般的内存空间，适用于存活对象比较少的情况。
- 标记-整理算法：首先进行标记，然后将所有存活的对象移动到内存的一端，然后清除另一端的所有对象。这个算法的优点是不会产生内存碎片，但是需要移动对象，影响效率。
- 分代收集算法：将内存分成多个代，每个代存活时间不同，每次只对某些代进行垃圾回收。通常将新对象分配到年轻代中，老对象分配到老年代中。
  这个算法的优点是能够针对不同的对象进行优化，提高效率。

---
### 分代收集流程
分代收集算法将堆内存分为新生代和老年代。

新生代回收时，会将活着的对象复制到另一个空间，原来的空间清理掉，这个过程叫Minor GC；

当对象在新生代回收过很多次还存在的时候，会被晋升到老年代，当老年代满了的时候会发生Full GC，针对老年代会使用标记-清除和标记-整理算法。

---
### 为什么采用分代回收算法
分代收集会根据对象的生命周期长短，将内存划分成不同的代，对不同代采用不同的回收频率和回收算法，提高回收效率，降低性能开销。

1. 大部分对象存活时间短
2. 少数对象存活时间长

- 减少内存碎片：新生代通过复制算法整理内存，无碎片；老年代通过标记-整理算法压缩内存；
- 减少STW时间

---
### 三色标记？

三色标记会把对象标记成三种颜色：
1. 白色：初始状态下，所有对象都是白色，表示没有被垃圾收集器访问过，如果最终标记完成后还是白色，说明这些对象是不可达的，可以被回收；
2. 灰色：灰色的对象表示已经被垃圾收集器发现并且至少存在一个对该对象的引用，但是该对象引用的其他对象还没有被完全扫描完毕；
3. 黑色：黑色对象表示不仅自己已经被标记为存活，而且它的所有引用也已经被处理过。

三色标记的过程：
1. 初始化阶段：所有对象都是白色的，从根集合中的对象开始标记成灰色，并且加入到待处理列表中；
2. 标记阶段：标记阶段从灰色对象开始，检查它所引用的所有对象；
- 如果被引用对象是白色，将它标记成灰色，加入到待处理列表中；
- 如果被引用对象已经是灰色或黑色，就不用处理；
3. 完成阶段：当没有灰色对象需要被处理时候，标记阶段结果；这个时候，如果还有白色对象剩余，就认为是不可达的垃圾，可以被回收；

但是因为应用线程和垃圾收集线程同时运行，所以会导致一些问题，比如"悬挂指针"问题。这个时候可以用一下策略解决：
1. 写屏障：每次修改对象图时候，都会触发写屏障机制。可以记录对象间引用关系的变化；
2. 增量更新(Incremental Update)或原始快照(SATB): SATB记录在GC开始前已经存在的对象状态；

---
### 老年区的回收算法

标记-整理

---
### 说一下快排思路？

快排的基本思想就是选择一个基准元素，然后将数组划分为两个子数组，使一个子数组中的元素都小于基准元素，另一个子数组中的元素都大于基准元素，然后对两个子数组递归进行快速排序，最后将两个子数组合并起来。

具体的实现过程如下：

1. 选择基准元素：从待排序数组中选择一个元素作为基准元素，通常是选择第一个元素或最后一个元素。
2. 然后划分子数组：将数组中的其余元素划分成两个子数组，其中一个子数组中的所有元素都小于基准元素，另一个子数组中的所有元素都大于基准元素，基准元素的位置也就确定了。
3. 然后递归排序子数组：对两个子数组分别递归进行快速排序，直到子数组中只剩下一个元素或没有元素。
4. 最后合并子数组：将已经排序好的两个子数组合并起来，得到最终的排序结果。

---
### 快排原理？

快排的基本思想是分治法，排序过程如下在输入数组中随机选取一个元素作为中间值pivot，然后对数组进行分区partition，使所有比中间值小的数据移到数组的左边，
所有比中间值大的数据移到数组的右边。接下来对中间值左右两侧的子数组用相同的步骤排序，直到子数组中只有一个数字为止。

---
### 快排，数组对于快排的影响？

快排的时间复杂度取决于所选取的中间值在数组中的位置。如果每次选取的中间值在排序数组中都接近数组中间的位置，那么快速排序的时间复杂度是O(nlogn)。
如果每次选取的中间值都位于排序数组的头部或尾部，那么快速排序的时间复杂度是O(n^2)。这也是随机选取中间值的原因，避免在某些情况下快速排序退化成时间复杂度为O(n^2)的算法。

---
### Collections中采用的排序方式是哪一种？具体是怎么使用的？

mergeSort和TimSort

---
### 归并排序的应用场景？空间复杂度？快排的空间复杂度是多少？

归并时间复杂度O(nlogn),空间复杂度O(n)，需要辅助数组
快排平均时间复杂度O(nlogn)，最坏O(n^2)，空间复杂度平均O(logn),最坏O(n)

---
### 代理 反射

---
### 编译时生成代理类

---
### 代码生成

---
### 字节码增强

---
### 深拷贝与浅拷贝的实际应用场景？

---
### 双亲委派模型的优势及破坏该模型的场景？
- 子类加载器收到类加载请求时候，会先委托父类加载器加载
- 父类加载器继续委托，直到启动类加载器
- 如果父类加载器无法加载，子类加载器才尝试自己加载

优势：
1. 避免类的重复加载，比如：所有类共享一个Object实例
2. 不影响核心API的类的加载
3. 实现模块化。通过自定义类加载器，可以实现运行时动态加载类，(比如插件系统),不影响已加载的类。

破坏双亲委派模型的场景：
1. SPI机制：SPI的接口由核心类加载器加载，但实现类由应用类加载器加载。
2. 模块化系统
3. 热部署：需要在运行时替换类

---
### 为什么需要双亲委派机制？如何打破？
1. 避免类的重复加载
2. 保护核心api不被篡改
3. 不同类加载器负责不同路径

如何打破：
1. 继承ClassLoader类，重写loadClass方法

---
### 怎么停止线程？
1. 通过设置标志位停止线程(在生安模型的项目里，设置boolean变量，判断是否还在推演中，如果推演结束了，就停止线程(在run方法里直接返回))
2. 调用Thread.stop()方法停止线程，这种方式会直接停止线程的执行，可能导致资源泄漏问题，不太安全。
